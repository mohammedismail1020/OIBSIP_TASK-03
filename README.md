<h1>Data Cleaning</h1>
<h2>Description</h2>
This project was completed as part of my internship at Oasis Info Tech. The task involved cleaning a dataset to ensure accuracy, consistency, and reliability. Data cleaning is an essential step in the data analysis process, as it removes or corrects erroneous, duplicate, or incomplete data, resulting in a dataset that is ready for further analysis or modeling.

Key tasks involved in this project include handling missing values, removing duplicate entries, correcting inconsistencies, and standardizing formats. The final outcome was a new, cleaned dataset that can be used for accurate and insightful analysis.

<h2>Features</h2>
Data Integrity: Ensured that the data remains accurate, consistent, and reliable by fixing errors and verifying data accuracy.

Missing Data Handling: Managed missing values by either imputing them with appropriate values or removing records with extensive missing fields.

Duplicate Removal: Identified and removed duplicate entries to maintain dataset uniqueness and prevent skewed results.

Data Standardization: Applied consistent formatting to date fields, text columns, and numeric values, ensuring uniformity across the dataset.

Outlier Detection: Detected and addressed outliers in numerical data to improve the quality of insights derived from the dataset.

Final Cleaned Dataset: Exported a new, reliable dataset ready for further analysis, machine learning, or reporting.

