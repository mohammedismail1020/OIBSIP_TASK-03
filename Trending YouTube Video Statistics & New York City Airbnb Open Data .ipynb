{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65fa9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pointbiserialr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be9f4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AB_NYC_2019.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c073524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Overview:\n",
      "     id                                              name  host_id  \\\n",
      "0  2539                Clean & quiet apt home by the park     2787   \n",
      "1  2595                             Skylit Midtown Castle     2845   \n",
      "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
      "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
      "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
      "\n",
      "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
      "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
      "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
      "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
      "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
      "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     Private room    149               1                  9  2018-10-19   \n",
      "1  Entire home/apt    225               1                 45  2019-05-21   \n",
      "2     Private room    150               3                  0         NaN   \n",
      "3  Entire home/apt     89               1                270  2019-07-05   \n",
      "4  Entire home/apt     80              10                  9  2018-11-19   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0               0.21                               6               365  \n",
      "1               0.38                               2               355  \n",
      "2                NaN                               1               365  \n",
      "3               4.64                               1               194  \n",
      "4               0.10                               1                 0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Data Overview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec9ea7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. **Data Integrity:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99168a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Integrity Checks:\n",
      "Number of invalid price records: 0\n",
      "Number of invalid minimum nights records: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for invalid values (e.g., negative price or minimum_nights)\n",
    "print(\"\\nData Integrity Checks:\")\n",
    "# Price cannot be negative\n",
    "invalid_price = df[df['price'] < 0]\n",
    "print(f\"Number of invalid price records: {len(invalid_price)}\")\n",
    "# Minimum nights should not be less than 1\n",
    "invalid_nights = df[df['minimum_nights'] < 1]\n",
    "print(f\"Number of invalid minimum nights records: {len(invalid_nights)}\")\n",
    "\n",
    "# Remove invalid rows\n",
    "df = df[df['price'] >= 0]\n",
    "df = df[df['minimum_nights'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68d284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. **Missing Data Handling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec4fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Data Before Cleaning:\n",
      "id                                    0\n",
      "name                                 16\n",
      "host_id                               0\n",
      "host_name                            21\n",
      "neighbourhood_group                   0\n",
      "neighbourhood                         0\n",
      "latitude                              0\n",
      "longitude                             0\n",
      "room_type                             0\n",
      "price                                 0\n",
      "minimum_nights                        0\n",
      "number_of_reviews                     0\n",
      "last_review                       10052\n",
      "reviews_per_month                 10052\n",
      "calculated_host_listings_count        0\n",
      "availability_365                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"\\nMissing Data Before Cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handling missing values by imputing or dropping (example)\n",
    "df['reviews_per_month'].fillna(0, inplace=True)  # Filling NaN in 'reviews_per_month' with 0\n",
    "df.dropna(subset=['last_review'], inplace=True)  # Dropping rows where 'last_review' is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73f0814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. **Duplicate Removal:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b70d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Check:\n",
      "Number of duplicate records: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates based on a unique identifier like 'id'\n",
    "print(\"\\nDuplicate Check:\")\n",
    "duplicates = df[df.duplicated(subset='id')]\n",
    "print(f\"Number of duplicate records: {len(duplicates)}\")\n",
    "\n",
    "# Remove duplicate records\n",
    "df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5936ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. **Standardization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a28198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Converting 'price' to consistent units, if necessary (assume in $)\n",
    "# Also handling categorical values for 'room_type'\n",
    "df['room_type'] = df['room_type'].str.strip().str.lower()  # Standardize room type formatting\n",
    "\n",
    "# Example of standardizing formats for categorical variables (if any inconsistencies)\n",
    "df['neighbourhood_group'] = df['neighbourhood_group'].str.title()\n",
    "df['neighbourhood'] = df['neighbourhood'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc2cb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. **Outlier Detection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c730e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers detected in 'price': 775\n",
      "\n",
      "Cleaned Data Overview:\n",
      "     id                                              name  host_id  \\\n",
      "0  2539                Clean & quiet apt home by the park     2787   \n",
      "1  2595                             Skylit Midtown Castle     2845   \n",
      "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
      "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
      "5  5099         Large Cozy 1 BR Apartment In Midtown East     7322   \n",
      "\n",
      "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
      "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
      "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
      "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
      "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
      "5        Chris           Manhattan   Murray Hill  40.74767  -73.97500   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     private room    149               1                  9  2018-10-19   \n",
      "1  entire home/apt    225               1                 45  2019-05-21   \n",
      "3  entire home/apt     89               1                270  2019-07-05   \n",
      "4  entire home/apt     80              10                  9  2018-11-19   \n",
      "5  entire home/apt    200               3                 74  2019-06-22   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0               0.21                               6               365  \n",
      "1               0.38                               2               355  \n",
      "3               4.64                               1               194  \n",
      "4               0.10                               1                 0  \n",
      "5               0.59                               1               129  \n",
      "\n",
      "Cleaned dataset saved as 'cleaned_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Using Z-score or IQR for detecting outliers in 'price' and 'reviews_per_month'\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = stats.zscore(df['price'])\n",
    "df['z_price'] = z_scores\n",
    "\n",
    "# Filter for outliers where the Z-score is beyond a threshold (e.g., > 3 or < -3)\n",
    "outliers = df[(df['z_price'] > 3) | (df['z_price'] < -3)]\n",
    "print(f\"\\nOutliers detected in 'price': {len(outliers)}\")\n",
    "\n",
    "# Option to drop outliers\n",
    "df = df[(df['z_price'] <= 3) & (df['z_price'] >= -3)]\n",
    "\n",
    "# Drop the 'z_price' column as it's no longer needed\n",
    "df.drop(columns=['z_price'], inplace=True)\n",
    "\n",
    "# **Final cleaned dataset preview**\n",
    "print(\"\\nCleaned Data Overview:\")\n",
    "print(df.head())\n",
    "\n",
    "# **Export the cleaned dataset to a new CSV file**\n",
    "df.to_csv(\"cleaned_datasets.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03a572dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>ShapeId</th>\n",
       "      <th>ColorId</th>\n",
       "      <th>SignId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meta/27.png</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meta/0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta/1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta/10.png</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta/11.png</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path  ClassId  ShapeId  ColorId SignId\n",
       "0  Meta/27.png       27        0        0   1.32\n",
       "1   Meta/0.png        0        1        0   3.29\n",
       "2   Meta/1.png        1        1        0   3.29\n",
       "3  Meta/10.png       10        1        0   3.27\n",
       "4  Meta/11.png       11        0        0   1.22"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Meta.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e88b46d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Types:\n",
      " Path       object\n",
      "ClassId     int64\n",
      "ShapeId     int64\n",
      "ColorId     int64\n",
      "SignId     object\n",
      "dtype: object\n",
      "\n",
      "Unique values in 'SignId':\n",
      " ['1.32' '3.29' '3.27' '1.22' '2.3' '2.1' '2.2' '3.1' '3.3' '3.21' '1.39'\n",
      " '1.2' '1.1' '1.3.2' '1.13' '1.5.2' '1.37' '1.24' '1.33' '1.34' nan '1.36'\n",
      " '3.42' '4.2' '4.3' '4.1' '4.4' '4.5' '4.7' '4.8' '3.26' '3.28' '3.25']\n",
      "Filled missing values in 'ClassId' with median: 21.0\n",
      "Filled missing values in 'ShapeId' with median: 1.0\n",
      "Filled missing values in 'ColorId' with median: 0.0\n",
      "Filled missing values in 'SignId' with mode: 3.29\n",
      "Dropped 0 rows with missing 'Path'.\n",
      "Number of duplicate rows: 0\n",
      "Data shape after removing duplicates: (43, 5)\n",
      "Missing values after conversion to numeric:\n",
      " ClassId    0\n",
      "ShapeId    0\n",
      "ColorId    0\n",
      "SignId     2\n",
      "dtype: int64\n",
      "Number of outlier rows detected: 1\n",
      "Data shape after removing outliers: (40, 5)\n",
      "Missing values after cleaning:\n",
      " Path       0\n",
      "ClassId    0\n",
      "ShapeId    0\n",
      "ColorId    0\n",
      "SignId     0\n",
      "dtype: int64\n",
      "Data cleaning process completed. Cleaned dataset exported as 'cleaned_dataset_Meta.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Meta.csv\")\n",
    "\n",
    "# 1. Data Integrity: Ensuring accuracy and consistency\n",
    "print(\"Initial Data Types:\\n\", df.dtypes)\n",
    "print(\"\\nUnique values in 'SignId':\\n\", df['SignId'].unique())\n",
    "\n",
    "# 2. Handling Missing Data\n",
    "# Define a function to impute missing values based on column type\n",
    "def impute_missing_values(df, column):\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        median_value = df[column].median()\n",
    "        df[column].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled missing values in '{column}' with median: {median_value}\")\n",
    "    else:\n",
    "        mode_value = df[column].mode()[0]\n",
    "        df[column].fillna(mode_value, inplace=True)\n",
    "        print(f\"Filled missing values in '{column}' with mode: {mode_value}\")\n",
    "\n",
    "# Apply the imputation function to relevant columns\n",
    "for col in ['ClassId', 'ShapeId', 'ColorId', 'SignId']:\n",
    "    impute_missing_values(df, col)\n",
    "\n",
    "# Option 2: Drop rows with missing 'Path' (if critical)\n",
    "initial_row_count = df.shape[0]\n",
    "df.dropna(subset=['Path'], inplace=True)\n",
    "dropped_rows = initial_row_count - df.shape[0]\n",
    "print(f\"Dropped {dropped_rows} rows with missing 'Path'.\")\n",
    "\n",
    "# 3. Duplicate Removal\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Data shape after removing duplicates: {df.shape}\")\n",
    "\n",
    "# 4. Ensure columns are numeric for Z-score calculation\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "for col in ['ClassId', 'ShapeId', 'ColorId', 'SignId']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Check if there are any remaining non-numeric (NaN) values after conversion\n",
    "print(\"Missing values after conversion to numeric:\\n\", df[['ClassId', 'ShapeId', 'ColorId', 'SignId']].isnull().sum())\n",
    "\n",
    "# Optionally, impute or drop rows with remaining NaN values\n",
    "df.dropna(subset=['ClassId', 'ShapeId', 'ColorId', 'SignId'], inplace=True)\n",
    "\n",
    "# 5. Outlier Detection using Z-scores\n",
    "numeric_cols = ['ClassId', 'ShapeId', 'ColorId', 'SignId']\n",
    "\n",
    "# Calculate Z-scores and filter out outliers\n",
    "z_scores = df[numeric_cols].apply(zscore)\n",
    "outliers = (np.abs(z_scores) > 3).any(axis=1)\n",
    "num_outliers = outliers.sum()\n",
    "print(f\"Number of outlier rows detected: {num_outliers}\")\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[~outliers].copy()\n",
    "print(f\"Data shape after removing outliers: {df_cleaned.shape}\")\n",
    "\n",
    "# 6. Final Cleaning Check\n",
    "print(\"Missing values after cleaning:\\n\", df_cleaned.isnull().sum())\n",
    "\n",
    "# Export the cleaned dataset\n",
    "df_cleaned.to_csv(\"cleaned_dataset_Meta.csv\", index=False)\n",
    "print(\"Data cleaning process completed. Cleaned dataset exported as 'cleaned_dataset_Meta.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb858864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a66234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12630 entries, 0 to 12629\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Width    12630 non-null  int64 \n",
      " 1   Height   12630 non-null  int64 \n",
      " 2   Roi.X1   12630 non-null  int64 \n",
      " 3   Roi.Y1   12630 non-null  int64 \n",
      " 4   Roi.X2   12630 non-null  int64 \n",
      " 5   Roi.Y2   12630 non-null  int64 \n",
      " 6   ClassId  12630 non-null  int64 \n",
      " 7   Path     12630 non-null  object\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 789.5+ KB\n",
      "None\n",
      "              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n",
      "count  12630.000000  12630.000000  12630.000000  12630.000000  12630.000000   \n",
      "mean      50.507759     50.364450      5.998021      5.982423     44.864450   \n",
      "std       25.088483     23.698908      1.543954      1.427424     23.776102   \n",
      "min       25.000000     25.000000      1.000000      5.000000     20.000000   \n",
      "25%       34.000000     35.000000      5.000000      5.000000     29.000000   \n",
      "50%       43.000000     43.000000      6.000000      6.000000     38.000000   \n",
      "75%       58.000000     57.000000      6.000000      6.000000     53.000000   \n",
      "max      266.000000    232.000000     23.000000     19.000000    244.000000   \n",
      "\n",
      "             Roi.Y2       ClassId  \n",
      "count  12630.000000  12630.000000  \n",
      "mean      44.758116     15.551069  \n",
      "std       22.494697     11.947123  \n",
      "min       20.000000      0.000000  \n",
      "25%       29.000000      5.000000  \n",
      "50%       38.000000     12.000000  \n",
      "75%       52.000000     25.000000  \n",
      "max      212.000000     42.000000  \n",
      "Final Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12227 entries, 0 to 12629\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Width    12227 non-null  float64\n",
      " 1   Height   12227 non-null  float64\n",
      " 2   Roi.X1   12227 non-null  float64\n",
      " 3   Roi.Y1   12227 non-null  float64\n",
      " 4   Roi.X2   12227 non-null  float64\n",
      " 5   Roi.Y2   12227 non-null  float64\n",
      " 6   ClassId  12227 non-null  int64  \n",
      " 7   Path     12227 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 859.7+ KB\n",
      "None\n",
      "              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n",
      "count  12227.000000  12227.000000  12227.000000  12227.000000  12227.000000   \n",
      "mean      -0.119205     -0.116906     -0.134596     -0.132250     -0.117151   \n",
      "std        0.739411      0.758137      0.622065      0.651984      0.751255   \n",
      "min       -1.016752     -1.070322     -0.646431     -0.688276     -1.045816   \n",
      "25%       -0.658008     -0.690542     -0.646431     -0.688276     -0.667270   \n",
      "50%       -0.339124     -0.352961      0.001282      0.012314     -0.330784   \n",
      "75%        0.218923      0.195610      0.001282      0.012314      0.216005   \n",
      "max        2.969298      2.980658      2.592135      2.814675      2.907890   \n",
      "\n",
      "             Roi.Y2       ClassId  \n",
      "count  12227.000000  12227.000000  \n",
      "mean      -0.114741     15.480085  \n",
      "std        0.769785     12.016082  \n",
      "min       -1.100664      0.000000  \n",
      "25%       -0.700554      5.000000  \n",
      "50%       -0.344900     12.000000  \n",
      "75%        0.233037     25.000000  \n",
      "max        2.944894     42.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"Test.csv\")\n",
    "\n",
    "# Display initial data info\n",
    "print(\"Initial Data Information:\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# 1. **Data Integrity** - Check for data types and range issues\n",
    "# Convert Width, Height, ROI coordinates to numeric if needed\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 2. **Missing Data Handling**\n",
    "# Impute missing numeric data using mean or median\n",
    "imputer = SimpleImputer(strategy='mean')  # Can change to 'median' if necessary\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = imputer.fit_transform(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']])\n",
    "\n",
    "# Handle missing values in ClassId or Path (dropping if few, or filling with a default class)\n",
    "df['ClassId'].fillna('Unknown', inplace=True)  # You can change this strategy if needed\n",
    "df['Path'].fillna('No_Path', inplace=True)  # Replace with a valid placeholder or remove if necessary\n",
    "\n",
    "# 3. **Duplicate Removal**\n",
    "# Check for duplicate rows and remove them\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 4. **Standardization** - Normalize or scale relevant numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = scaler.fit_transform(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']])\n",
    "\n",
    "# 5. **Outlier Detection**\n",
    "# Identify and remove outliers using Z-score or IQR method\n",
    "\n",
    "# Using Z-score method\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs(stats.zscore(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']]))\n",
    "outliers = (z_scores > 3).any(axis=1)  # Mark outliers where Z-score > 3\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "df = df[~outliers]\n",
    "\n",
    "# Final Dataset Check\n",
    "print(\"Final Data Information:\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "df.to_csv(\"cleaned_dataset_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35679df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c8e0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39209 entries, 0 to 39208\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Width    39209 non-null  int64 \n",
      " 1   Height   39209 non-null  int64 \n",
      " 2   Roi.X1   39209 non-null  int64 \n",
      " 3   Roi.Y1   39209 non-null  int64 \n",
      " 4   Roi.X2   39209 non-null  int64 \n",
      " 5   Roi.Y2   39209 non-null  int64 \n",
      " 6   ClassId  39209 non-null  int64 \n",
      " 7   Path     39209 non-null  object\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n",
      "count  39209.000000  39209.000000  39209.000000  39209.000000  39209.000000   \n",
      "mean      50.835880     50.328930      5.999515      5.962381     45.197302   \n",
      "std       24.306933     23.115423      1.475493      1.385440     23.060157   \n",
      "min       25.000000     25.000000      0.000000      5.000000     20.000000   \n",
      "25%       35.000000     35.000000      5.000000      5.000000     29.000000   \n",
      "50%       43.000000     43.000000      6.000000      6.000000     38.000000   \n",
      "75%       58.000000     58.000000      6.000000      6.000000     53.000000   \n",
      "max      243.000000    225.000000     20.000000     20.000000    223.000000   \n",
      "\n",
      "             Roi.Y2       ClassId  \n",
      "count  39209.000000  39209.000000  \n",
      "mean      44.728379     15.788390  \n",
      "std       21.971145     12.013238  \n",
      "min       20.000000      0.000000  \n",
      "25%       30.000000      5.000000  \n",
      "50%       38.000000     12.000000  \n",
      "75%       52.000000     25.000000  \n",
      "max      205.000000     42.000000  \n",
      "Final Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38035 entries, 0 to 39208\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Width    38035 non-null  float64\n",
      " 1   Height   38035 non-null  float64\n",
      " 2   Roi.X1   38035 non-null  float64\n",
      " 3   Roi.Y1   38035 non-null  float64\n",
      " 4   Roi.X2   38035 non-null  float64\n",
      " 5   Roi.Y2   38035 non-null  float64\n",
      " 6   ClassId  38035 non-null  int64  \n",
      " 7   Path     38035 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n",
      "count  38035.000000  38035.000000  38035.000000  38035.000000  38035.000000   \n",
      "mean      -0.110086     -0.109211     -0.125439     -0.124798     -0.108082   \n",
      "std        0.771937      0.780125      0.666158      0.678540      0.782605   \n",
      "min       -1.062915     -1.095773     -2.710664     -0.694648     -1.092691   \n",
      "25%       -0.692646     -0.706417     -0.677420     -0.694648     -0.702402   \n",
      "50%       -0.322376     -0.360324      0.000328      0.027153     -0.355479   \n",
      "75%        0.212457      0.245340      0.000328      0.027153      0.251636   \n",
      "max        2.968908      2.970828      2.711320      2.914361      2.940291   \n",
      "\n",
      "             Roi.Y2       ClassId  \n",
      "count  38035.000000  38035.000000  \n",
      "mean      -0.107107     15.737058  \n",
      "std        0.790881     12.074197  \n",
      "min       -1.125508      0.000000  \n",
      "25%       -0.715874      5.000000  \n",
      "50%       -0.351756     12.000000  \n",
      "75%        0.285452     25.000000  \n",
      "max        2.925311     42.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"Train.csv\")\n",
    "\n",
    "# Display initial data info\n",
    "print(\"Initial Data Information:\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# 1. **Data Integrity** - Check for data types and range issues\n",
    "# Convert Width, Height, ROI coordinates to numeric if needed\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 2. **Missing Data Handling**\n",
    "# Impute missing numeric data using mean or median\n",
    "imputer = SimpleImputer(strategy='mean')  # Can change to 'median' if necessary\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = imputer.fit_transform(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']])\n",
    "\n",
    "# Handle missing values in ClassId or Path (dropping if few, or filling with a default class)\n",
    "df['ClassId'].fillna('Unknown', inplace=True)  # You can change this strategy if needed\n",
    "df['Path'].fillna('No_Path', inplace=True)  # Replace with a valid placeholder or remove if necessary\n",
    "\n",
    "# 3. **Duplicate Removal**\n",
    "# Check for duplicate rows and remove them\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 4. **Standardization** - Normalize or scale relevant numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']] = scaler.fit_transform(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']])\n",
    "\n",
    "# 5. **Outlier Detection**\n",
    "# Identify and remove outliers using Z-score or IQR method\n",
    "\n",
    "# Using Z-score method\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs(stats.zscore(df[['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']]))\n",
    "outliers = (z_scores > 3).any(axis=1)  # Mark outliers where Z-score > 3\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "df = df[~outliers]\n",
    "\n",
    "# Final Dataset Check\n",
    "print(\"Final Data Information:\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "df.to_csv(\"cleaned_dataset_Train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c9cdfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. Beyoncé</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787425</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Eminem's new track Walk on Water ft. Beyoncé i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dBIkQ4Mz1M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>PLUSH - Bad Unboxing Fan Mail</td>\n",
       "      <td>iDubbbzTV</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-13T17:00:00.000Z</td>\n",
       "      <td>plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...</td>\n",
       "      <td>1014651</td>\n",
       "      <td>127794</td>\n",
       "      <td>1688</td>\n",
       "      <td>13030</td>\n",
       "      <td>https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>STill got a lot of packages. Probably will las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146035</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095828</td>\n",
       "      <td>132239</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Vv-BfVoq4g</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Ed Sheeran - Perfect (Official Music Video)</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-09T11:04:14.000Z</td>\n",
       "      <td>edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...</td>\n",
       "      <td>33523622</td>\n",
       "      <td>1634130</td>\n",
       "      <td>21082</td>\n",
       "      <td>85067</td>\n",
       "      <td>https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>🎧: https://ad.gt/yt-perfect\\n💰: https://atlant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  n1WpP7iowLc      17.14.11   \n",
       "1  0dBIkQ4Mz1M      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  d380meD0W0M      17.14.11   \n",
       "4  2Vv-BfVoq4g      17.14.11   \n",
       "\n",
       "                                               title channel_title  \\\n",
       "0         Eminem - Walk On Water (Audio) ft. Beyoncé    EminemVEVO   \n",
       "1                      PLUSH - Bad Unboxing Fan Mail     iDubbbzTV   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...  Rudy Mancuso   \n",
       "3                           I Dare You: GOING BALD!?      nigahiga   \n",
       "4        Ed Sheeran - Perfect (Official Music Video)    Ed Sheeran   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           10  2017-11-10T17:00:03.000Z   \n",
       "1           23  2017-11-13T17:00:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-12T18:01:41.000Z   \n",
       "4           10  2017-11-09T11:04:14.000Z   \n",
       "\n",
       "                                                tags     views    likes  \\\n",
       "0  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579   787425   \n",
       "1  plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...   1014651   127794   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...   3191434   146035   \n",
       "3  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...   2095828   132239   \n",
       "4  edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...  33523622  1634130   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
       "1      1688          13030  https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "4     21082          85067  https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Eminem's new track Walk on Water ft. Beyoncé i...  \n",
       "1  STill got a lot of packages. Probably will las...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  I know it's been a while since we did this sho...  \n",
       "4  🎧: https://ad.gt/yt-perfect\\n💰: https://atlant...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"CAvideos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "001d503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40881 entries, 0 to 40880\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40881 non-null  object\n",
      " 1   trending_date           40881 non-null  object\n",
      " 2   title                   40881 non-null  object\n",
      " 3   channel_title           40881 non-null  object\n",
      " 4   category_id             40881 non-null  int64 \n",
      " 5   publish_time            40881 non-null  object\n",
      " 6   tags                    40881 non-null  object\n",
      " 7   views                   40881 non-null  int64 \n",
      " 8   likes                   40881 non-null  int64 \n",
      " 9   dislikes                40881 non-null  int64 \n",
      " 10  comment_count           40881 non-null  int64 \n",
      " 11  thumbnail_link          40881 non-null  object\n",
      " 12  comments_disabled       40881 non-null  bool  \n",
      " 13  ratings_disabled        40881 non-null  bool  \n",
      " 14  video_error_or_removed  40881 non-null  bool  \n",
      " 15  description             39585 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40881.000000  4.088100e+04  4.088100e+04  4.088100e+04   4.088100e+04\n",
      "mean      20.795553  1.147036e+06  3.958269e+04  2.009195e+03   5.042975e+03\n",
      "std        6.775054  3.390913e+06  1.326895e+05  1.900837e+04   2.157902e+04\n",
      "min        1.000000  7.330000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       20.000000  1.439020e+05  2.191000e+03  9.900000e+01   4.170000e+02\n",
      "50%       24.000000  3.712040e+05  8.780000e+03  3.030000e+02   1.301000e+03\n",
      "75%       24.000000  9.633020e+05  2.871700e+04  9.500000e+02   3.713000e+03\n",
      "max       43.000000  1.378431e+08  5.053338e+06  1.602383e+06   1.114800e+06\n",
      "[10 23 24 25 22 26  1 28 20 17 29 15 19  2 27 43 30]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               1296\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "Outliers in Views: 554\n",
      "Outliers in Likes: 479\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40154 entries, 1 to 40880\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                40154 non-null  object             \n",
      " 1   trending_date           40154 non-null  datetime64[ns]     \n",
      " 2   title                   40154 non-null  object             \n",
      " 3   channel_title           40154 non-null  object             \n",
      " 4   category_id             40154 non-null  int64              \n",
      " 5   publish_time            40154 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    40154 non-null  object             \n",
      " 7   views                   40154 non-null  int64              \n",
      " 8   likes                   40154 non-null  int64              \n",
      " 9   dislikes                40154 non-null  int64              \n",
      " 10  comment_count           40154 non-null  int64              \n",
      " 11  thumbnail_link          40154 non-null  object             \n",
      " 12  comments_disabled       40154 non-null  bool               \n",
      " 13  ratings_disabled        40154 non-null  bool               \n",
      " 14  video_error_or_removed  40154 non-null  bool               \n",
      " 15  description             40154 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          40154  40154.000000  4.015400e+04   \n",
      "mean   2018-02-27 04:57:15.573043712     20.906684  8.258698e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  7.330000e+02   \n",
      "25%              2018-01-04 00:00:00     20.000000  1.413355e+05   \n",
      "50%              2018-02-26 00:00:00     24.000000  3.595730e+05   \n",
      "75%              2018-04-24 00:00:00     24.000000  9.107290e+05   \n",
      "max              2018-06-14 00:00:00     43.000000  1.131912e+07   \n",
      "std                              NaN      6.711252  1.306882e+06   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   40154.000000   40154.000000   40154.000000  \n",
      "mean    27763.176072    1281.058101    3673.956567  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%      2141.000000      96.000000     406.000000  \n",
      "50%      8391.000000     291.500000    1259.000000  \n",
      "75%     26844.250000     887.000000    3506.000000  \n",
      "max    435048.000000  439353.000000  349112.000000  \n",
      "std     52788.002730    5659.339551    8258.806857  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('CAvideos.csv')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_CAvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ddf3785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LgVi6y5QIjM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Sing zu Ende! | Gesangseinlagen vom Feinsten |...</td>\n",
       "      <td>inscope21</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T17:08:49.000Z</td>\n",
       "      <td>inscope21|\"sing zu ende\"|\"gesangseinlagen\"|\"ge...</td>\n",
       "      <td>252786</td>\n",
       "      <td>35885</td>\n",
       "      <td>230</td>\n",
       "      <td>1539</td>\n",
       "      <td>https://i.ytimg.com/vi/LgVi6y5QIjM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Heute gibt es mal wieder ein neues Format... w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayt7uQith4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Kinder ferngesteuert im Kiosk! Erwachsene abzo...</td>\n",
       "      <td>LUKE! Die Woche und ich</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T22:30:01.000Z</td>\n",
       "      <td>Kinder|\"ferngesteuert\"|\"Kinder ferngesteuert\"|...</td>\n",
       "      <td>797196</td>\n",
       "      <td>53576</td>\n",
       "      <td>302</td>\n",
       "      <td>1278</td>\n",
       "      <td>https://i.ytimg.com/vi/Bayt7uQith4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kinder ferngesteuert! Kinder lassen sich sooo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97190</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHtypnRk7JE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Das Fermi-Paradoxon</td>\n",
       "      <td>100SekundenPhysik</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-11-12T15:00:01.000Z</td>\n",
       "      <td>Physik|\"Wissenschaft\"|\"Technik\"|\"Science-Ficti...</td>\n",
       "      <td>380247</td>\n",
       "      <td>31821</td>\n",
       "      <td>458</td>\n",
       "      <td>1955</td>\n",
       "      <td>https://i.ytimg.com/vi/AHtypnRk7JE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>►Alle Videos: http://bit.ly/1fa7Tw3\\n\\n\\n✚Snap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJ9We4bjcg0</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>18 SONGS mit Kelly MissesVlog (Sing-off)</td>\n",
       "      <td>rezo</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T13:10:36.000Z</td>\n",
       "      <td>kelly|\"missesvlog\"|\"kelly song\"|\"bausa\"|\"bausa...</td>\n",
       "      <td>822213</td>\n",
       "      <td>100684</td>\n",
       "      <td>2467</td>\n",
       "      <td>10244</td>\n",
       "      <td>https://i.ytimg.com/vi/ZJ9We4bjcg0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18 Song Mashup über den (veränderten) Beat von...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  LgVi6y5QIjM      17.14.11   \n",
       "1  Bayt7uQith4      17.14.11   \n",
       "2  1ZAPwfrtAFY      17.14.11   \n",
       "3  AHtypnRk7JE      17.14.11   \n",
       "4  ZJ9We4bjcg0      17.14.11   \n",
       "\n",
       "                                               title            channel_title  \\\n",
       "0  Sing zu Ende! | Gesangseinlagen vom Feinsten |...                inscope21   \n",
       "1  Kinder ferngesteuert im Kiosk! Erwachsene abzo...  LUKE! Die Woche und ich   \n",
       "2  The Trump Presidency: Last Week Tonight with J...          LastWeekTonight   \n",
       "3                                Das Fermi-Paradoxon        100SekundenPhysik   \n",
       "4           18 SONGS mit Kelly MissesVlog (Sing-off)                     rezo   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           24  2017-11-13T17:08:49.000Z   \n",
       "1           23  2017-11-12T22:30:01.000Z   \n",
       "2           24  2017-11-13T07:30:00.000Z   \n",
       "3           27  2017-11-12T15:00:01.000Z   \n",
       "4           24  2017-11-12T13:10:36.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0  inscope21|\"sing zu ende\"|\"gesangseinlagen\"|\"ge...   252786   35885   \n",
       "1  Kinder|\"ferngesteuert\"|\"Kinder ferngesteuert\"|...   797196   53576   \n",
       "2  last week tonight trump presidency|\"last week ...  2418783   97190   \n",
       "3  Physik|\"Wissenschaft\"|\"Technik\"|\"Science-Ficti...   380247   31821   \n",
       "4  kelly|\"missesvlog\"|\"kelly song\"|\"bausa\"|\"bausa...   822213  100684   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0       230           1539  https://i.ytimg.com/vi/LgVi6y5QIjM/default.jpg   \n",
       "1       302           1278  https://i.ytimg.com/vi/Bayt7uQith4/default.jpg   \n",
       "2      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "3       458           1955  https://i.ytimg.com/vi/AHtypnRk7JE/default.jpg   \n",
       "4      2467          10244  https://i.ytimg.com/vi/ZJ9We4bjcg0/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Heute gibt es mal wieder ein neues Format... w...  \n",
       "1  Kinder ferngesteuert! Kinder lassen sich sooo ...  \n",
       "2  One year after the presidential election, John...  \n",
       "3  ►Alle Videos: http://bit.ly/1fa7Tw3\\n\\n\\n✚Snap...  \n",
       "4  18 Song Mashup über den (veränderten) Beat von...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DEvideos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c599866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40840 entries, 0 to 40839\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40840 non-null  object\n",
      " 1   trending_date           40840 non-null  object\n",
      " 2   title                   40840 non-null  object\n",
      " 3   channel_title           40840 non-null  object\n",
      " 4   category_id             40840 non-null  int64 \n",
      " 5   publish_time            40840 non-null  object\n",
      " 6   tags                    40840 non-null  object\n",
      " 7   views                   40840 non-null  int64 \n",
      " 8   likes                   40840 non-null  int64 \n",
      " 9   dislikes                40840 non-null  int64 \n",
      " 10  comment_count           40840 non-null  int64 \n",
      " 11  thumbnail_link          40840 non-null  object\n",
      " 12  comments_disabled       40840 non-null  bool  \n",
      " 13  ratings_disabled        40840 non-null  bool  \n",
      " 14  video_error_or_removed  40840 non-null  bool  \n",
      " 15  description             39288 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40840.000000  4.084000e+04  4.084000e+04  4.084000e+04   4.084000e+04\n",
      "mean      20.705828  6.034553e+05  2.187550e+04  1.397136e+03   2.785857e+03\n",
      "std        6.975813  2.348963e+06  1.018000e+05  1.457738e+04   1.745803e+04\n",
      "min        1.000000  5.180000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       20.000000  2.706875e+04  5.330000e+02  2.900000e+01   7.900000e+01\n",
      "50%       24.000000  1.192770e+05  2.699000e+03  1.340000e+02   3.760000e+02\n",
      "75%       24.000000  4.431015e+05  1.179625e+04  5.320000e+02   1.376000e+03\n",
      "max       44.000000  1.138762e+08  4.924056e+06  1.470386e+06   1.084435e+06\n",
      "[24 23 27 22  1  2 17 26 25 10 20 43 28 29 15 19 44 30]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               1552\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "Outliers in Views: 441\n",
      "Outliers in Likes: 409\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40262 entries, 0 to 40839\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                40262 non-null  object             \n",
      " 1   trending_date           40262 non-null  datetime64[ns]     \n",
      " 2   title                   40262 non-null  object             \n",
      " 3   channel_title           40262 non-null  object             \n",
      " 4   category_id             40262 non-null  int64              \n",
      " 5   publish_time            40262 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    40262 non-null  object             \n",
      " 7   views                   40262 non-null  int64              \n",
      " 8   likes                   40262 non-null  int64              \n",
      " 9   dislikes                40262 non-null  int64              \n",
      " 10  comment_count           40262 non-null  int64              \n",
      " 11  thumbnail_link          40262 non-null  object             \n",
      " 12  comments_disabled       40262 non-null  bool               \n",
      " 13  ratings_disabled        40262 non-null  bool               \n",
      " 14  video_error_or_removed  40262 non-null  bool               \n",
      " 15  description             40262 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          40262  40262.000000  4.026200e+04   \n",
      "mean   2018-02-26 22:15:27.405493760     20.785828  4.087023e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  5.180000e+02   \n",
      "25%              2018-01-03 00:00:00     22.000000  2.642775e+04   \n",
      "50%              2018-02-26 00:00:00     24.000000  1.148605e+05   \n",
      "75%              2018-04-24 00:00:00     24.000000  4.186290e+05   \n",
      "max              2018-06-14 00:00:00     44.000000  7.644908e+06   \n",
      "std                              NaN      6.932554  7.795390e+05   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   40262.000000   40262.000000   40262.000000  \n",
      "mean    13938.741766     900.869728    1795.981447  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%       518.000000      28.000000      77.000000  \n",
      "50%      2597.000000     129.000000     362.000000  \n",
      "75%     11024.000000     498.000000    1299.000000  \n",
      "max    327096.000000  244229.000000  143819.000000  \n",
      "std     33490.509742    4453.148549    4904.407686  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('DEvideos.csv')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_DEvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cdde040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ro6eob0LrCY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Malika LePen : Femme de Gauche - Trailer</td>\n",
       "      <td>Le Raptor Dissident</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T17:32:55.000Z</td>\n",
       "      <td>Raptor\"|\"Dissident\"|\"Expliquez\"|\"moi\"|\"cette\"|...</td>\n",
       "      <td>212702</td>\n",
       "      <td>29282</td>\n",
       "      <td>1108</td>\n",
       "      <td>3817</td>\n",
       "      <td>https://i.ytimg.com/vi/Ro6eob0LrCY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dimanche.\\n18h30.\\nSoyez présents pour la vidé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yo84eqYwP98</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...</td>\n",
       "      <td>Le Labo</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T15:00:02.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>432721</td>\n",
       "      <td>14053</td>\n",
       "      <td>576</td>\n",
       "      <td>1161</td>\n",
       "      <td>https://i.ytimg.com/vi/Yo84eqYwP98/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Le jeu de société: https://goo.gl/hhG1Ta\\n\\nGa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ceqntSXE-10</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...</td>\n",
       "      <td>Daniil le Russe</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-13T17:00:38.000Z</td>\n",
       "      <td>cartoon\"|\"pokémon\"|\"école\"|\"ours\"|\"мультфильм</td>\n",
       "      <td>482153</td>\n",
       "      <td>76203</td>\n",
       "      <td>477</td>\n",
       "      <td>9580</td>\n",
       "      <td>https://i.ytimg.com/vi/ceqntSXE-10/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Une nouvelle dose de dessins animés français e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WuTFI5qftCE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>PAPY GRENIER - METAL GEAR SOLID</td>\n",
       "      <td>Joueur Du Grenier</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-11-12T17:00:02.000Z</td>\n",
       "      <td>Papy grenier\"|\"Metal Gear Solid\"|\"PS1\"|\"Tirage...</td>\n",
       "      <td>925222</td>\n",
       "      <td>85016</td>\n",
       "      <td>550</td>\n",
       "      <td>4303</td>\n",
       "      <td>https://i.ytimg.com/vi/WuTFI5qftCE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nouvel ,épisode de Papy Grenier ! Ce mois-ci o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ee6OFs8TdEg</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...</td>\n",
       "      <td>Aurelien Fontenoy</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T16:30:03.000Z</td>\n",
       "      <td>vélo\"|\"vtt\"|\"bmx\"|\"freestyle\"|\"bike\"|\"mtb\"|\"di...</td>\n",
       "      <td>141695</td>\n",
       "      <td>8091</td>\n",
       "      <td>72</td>\n",
       "      <td>481</td>\n",
       "      <td>https://i.ytimg.com/vi/ee6OFs8TdEg/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sauts à plus de 4 mètres de haut dans un tramp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  Ro6eob0LrCY      17.14.11   \n",
       "1  Yo84eqYwP98      17.14.11   \n",
       "2  ceqntSXE-10      17.14.11   \n",
       "3  WuTFI5qftCE      17.14.11   \n",
       "4  ee6OFs8TdEg      17.14.11   \n",
       "\n",
       "                                               title        channel_title  \\\n",
       "0           Malika LePen : Femme de Gauche - Trailer  Le Raptor Dissident   \n",
       "1  LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...              Le Labo   \n",
       "2  DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...      Daniil le Russe   \n",
       "3                    PAPY GRENIER - METAL GEAR SOLID    Joueur Du Grenier   \n",
       "4  QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...    Aurelien Fontenoy   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           24  2017-11-13T17:32:55.000Z   \n",
       "1           24  2017-11-12T15:00:02.000Z   \n",
       "2           23  2017-11-13T17:00:38.000Z   \n",
       "3           20  2017-11-12T17:00:02.000Z   \n",
       "4           17  2017-11-13T16:30:03.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  Raptor\"|\"Dissident\"|\"Expliquez\"|\"moi\"|\"cette\"|...  212702  29282      1108   \n",
       "1                                             [none]  432721  14053       576   \n",
       "2      cartoon\"|\"pokémon\"|\"école\"|\"ours\"|\"мультфильм  482153  76203       477   \n",
       "3  Papy grenier\"|\"Metal Gear Solid\"|\"PS1\"|\"Tirage...  925222  85016       550   \n",
       "4  vélo\"|\"vtt\"|\"bmx\"|\"freestyle\"|\"bike\"|\"mtb\"|\"di...  141695   8091        72   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0           3817  https://i.ytimg.com/vi/Ro6eob0LrCY/default.jpg   \n",
       "1           1161  https://i.ytimg.com/vi/Yo84eqYwP98/default.jpg   \n",
       "2           9580  https://i.ytimg.com/vi/ceqntSXE-10/default.jpg   \n",
       "3           4303  https://i.ytimg.com/vi/WuTFI5qftCE/default.jpg   \n",
       "4            481  https://i.ytimg.com/vi/ee6OFs8TdEg/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Dimanche.\\n18h30.\\nSoyez présents pour la vidé...  \n",
       "1  Le jeu de société: https://goo.gl/hhG1Ta\\n\\nGa...  \n",
       "2  Une nouvelle dose de dessins animés français e...  \n",
       "3  Nouvel ,épisode de Papy Grenier ! Ce mois-ci o...  \n",
       "4  Sauts à plus de 4 mètres de haut dans un tramp...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"FRvideos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22ac0278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40724 entries, 0 to 40723\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40724 non-null  object\n",
      " 1   trending_date           40724 non-null  object\n",
      " 2   title                   40724 non-null  object\n",
      " 3   channel_title           40724 non-null  object\n",
      " 4   category_id             40724 non-null  int64 \n",
      " 5   publish_time            40724 non-null  object\n",
      " 6   tags                    40724 non-null  object\n",
      " 7   views                   40724 non-null  int64 \n",
      " 8   likes                   40724 non-null  int64 \n",
      " 9   dislikes                40724 non-null  int64 \n",
      " 10  comment_count           40724 non-null  int64 \n",
      " 11  thumbnail_link          40724 non-null  object\n",
      " 12  comments_disabled       40724 non-null  bool  \n",
      " 13  ratings_disabled        40724 non-null  bool  \n",
      " 14  video_error_or_removed  40724 non-null  bool  \n",
      " 15  description             37812 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40724.000000  4.072400e+04  4.072400e+04  4.072400e+04   4.072400e+04\n",
      "mean      20.123809  4.199219e+05  1.738886e+04  8.149624e+02   1.832453e+03\n",
      "std        6.984422  1.772130e+06  8.720509e+04  1.139219e+04   1.404321e+04\n",
      "min        1.000000  2.230000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       17.000000  1.697450e+04  3.380000e+02  1.800000e+01   5.600000e+01\n",
      "50%       23.000000  7.372100e+04  1.892500e+03  8.300000e+01   2.350000e+02\n",
      "75%       24.000000  2.708088e+05  7.969500e+03  3.350000e+02   8.410000e+02\n",
      "max       44.000000  1.009116e+08  4.750254e+06  1.353661e+06   1.040912e+06\n",
      "[24 23 20 17 22 27 26 28  2 25  1 10 43 19 15 29 30 44]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               2912\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "Outliers in Views: 388\n",
      "Outliers in Likes: 408\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40168 entries, 0 to 40723\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                40168 non-null  object             \n",
      " 1   trending_date           40168 non-null  datetime64[ns]     \n",
      " 2   title                   40168 non-null  object             \n",
      " 3   channel_title           40168 non-null  object             \n",
      " 4   category_id             40168 non-null  int64              \n",
      " 5   publish_time            40168 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    40168 non-null  object             \n",
      " 7   views                   40168 non-null  int64              \n",
      " 8   likes                   40168 non-null  int64              \n",
      " 9   dislikes                40168 non-null  int64              \n",
      " 10  comment_count           40168 non-null  int64              \n",
      " 11  thumbnail_link          40168 non-null  object             \n",
      " 12  comments_disabled       40168 non-null  bool               \n",
      " 13  ratings_disabled        40168 non-null  bool               \n",
      " 14  video_error_or_removed  40168 non-null  bool               \n",
      " 15  description             40168 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          40168  40168.000000  4.016800e+04   \n",
      "mean   2018-02-26 19:51:33.806014720     20.187214  2.785682e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  2.230000e+02   \n",
      "25%              2018-01-03 00:00:00     17.000000  1.659450e+04   \n",
      "50%              2018-02-25 00:00:00     23.000000  7.099700e+04   \n",
      "75%              2018-04-24 00:00:00     24.000000  2.552382e+05   \n",
      "max              2018-06-14 00:00:00     44.000000  5.706064e+06   \n",
      "std                              NaN      6.958606  5.719629e+05   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   40168.000000   40168.000000   40168.000000  \n",
      "mean    10781.467661     438.445031    1077.592337  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%       330.000000      17.000000      54.000000  \n",
      "50%      1819.500000      80.000000     227.000000  \n",
      "75%      7442.250000     315.000000     798.000000  \n",
      "max    278949.000000  115658.000000   74458.000000  \n",
      "std     27617.674301    1698.019486    3119.574688  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('FRvideos.csv')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_FRvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f52fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>christmas|\"john lewis christmas\"|\"john lewis\"|...</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Click here to continue the story and make your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3s1rvMFUweQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Taylor Swift: …Ready for It? (Live) - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T06:24:44.000Z</td>\n",
       "      <td>SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...</td>\n",
       "      <td>1053632</td>\n",
       "      <td>25561</td>\n",
       "      <td>2294</td>\n",
       "      <td>2757</td>\n",
       "      <td>https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Musical guest Taylor Swift performs …Ready for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. Beyoncé</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787420</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Eminem's new track Walk on Water ft. Beyoncé i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUTEiSjKwJU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Goals from Salford City vs Class of 92 and Fri...</td>\n",
       "      <td>Salford City Football Club</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:30:38.000Z</td>\n",
       "      <td>Salford City FC|\"Salford City\"|\"Salford\"|\"Clas...</td>\n",
       "      <td>27833</td>\n",
       "      <td>193</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Salford drew 4-4 against the Class of 92 and F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rHwDegptbI4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "      <td>Cute Girl Videos</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T01:45:13.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>9815</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>https://i.ytimg.com/vi/rHwDegptbI4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  Jw1Y-zhQURU      17.14.11   \n",
       "1  3s1rvMFUweQ      17.14.11   \n",
       "2  n1WpP7iowLc      17.14.11   \n",
       "3  PUTEiSjKwJU      17.14.11   \n",
       "4  rHwDegptbI4      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0      John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "1          Taylor Swift: …Ready for It? (Live) - SNL   \n",
       "2         Eminem - Walk On Water (Audio) ft. Beyoncé   \n",
       "3  Goals from Salford City vs Class of 92 and Fri...   \n",
       "4  Dashcam captures truck's near miss with child ...   \n",
       "\n",
       "                channel_title  category_id              publish_time  \\\n",
       "0                  John Lewis           26  2017-11-10T07:38:29.000Z   \n",
       "1         Saturday Night Live           24  2017-11-12T06:24:44.000Z   \n",
       "2                  EminemVEVO           10  2017-11-10T17:00:03.000Z   \n",
       "3  Salford City Football Club           17  2017-11-13T02:30:38.000Z   \n",
       "4            Cute Girl Videos           25  2017-11-13T01:45:13.000Z   \n",
       "\n",
       "                                                tags     views   likes  \\\n",
       "0  christmas|\"john lewis christmas\"|\"john lewis\"|...   7224515   55681   \n",
       "1  SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...   1053632   25561   \n",
       "2  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579  787420   \n",
       "3  Salford City FC|\"Salford City\"|\"Salford\"|\"Clas...     27833     193   \n",
       "4                                             [none]      9815      30   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     10247           9479  https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg   \n",
       "1      2294           2757  https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg   \n",
       "2     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
       "3        12             37  https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg   \n",
       "4         2             30  https://i.ytimg.com/vi/rHwDegptbI4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Click here to continue the story and make your...  \n",
       "1  Musical guest Taylor Swift performs …Ready for...  \n",
       "2  Eminem's new track Walk on Water ft. Beyoncé i...  \n",
       "3  Salford drew 4-4 against the Class of 92 and F...  \n",
       "4  Dashcam captures truck's near miss with child ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"GBvideos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac89790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38916 entries, 0 to 38915\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                38916 non-null  object\n",
      " 1   trending_date           38916 non-null  object\n",
      " 2   title                   38916 non-null  object\n",
      " 3   channel_title           38916 non-null  object\n",
      " 4   category_id             38916 non-null  int64 \n",
      " 5   publish_time            38916 non-null  object\n",
      " 6   tags                    38916 non-null  object\n",
      " 7   views                   38916 non-null  int64 \n",
      " 8   likes                   38916 non-null  int64 \n",
      " 9   dislikes                38916 non-null  int64 \n",
      " 10  comment_count           38916 non-null  int64 \n",
      " 11  thumbnail_link          38916 non-null  object\n",
      " 12  comments_disabled       38916 non-null  bool  \n",
      " 13  ratings_disabled        38916 non-null  bool  \n",
      " 14  video_error_or_removed  38916 non-null  bool  \n",
      " 15  description             38304 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.0+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  38916.000000  3.891600e+04  3.891600e+04  3.891600e+04   3.891600e+04\n",
      "mean      16.827937  5.911944e+06  1.345196e+05  7.612560e+03   1.308835e+04\n",
      "std        7.752728  1.900121e+07  3.499893e+05  5.095683e+04   5.066740e+04\n",
      "min        1.000000  8.510000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       10.000000  2.515272e+05  5.897000e+03  2.000000e+02   6.790000e+02\n",
      "50%       20.000000  9.818890e+05  2.518250e+04  8.210000e+02   2.478000e+03\n",
      "75%       24.000000  3.683628e+06  1.140892e+05  3.357500e+03   9.241500e+03\n",
      "max       43.000000  4.245389e+08  5.613827e+06  1.944971e+06   1.626501e+06\n",
      "[26 24 10 17 25 22 23 28 15 27  1 20  2 19 29 43]\n",
      "[False  True]\n",
      "video_id                    0\n",
      "trending_date               0\n",
      "title                       0\n",
      "channel_title               0\n",
      "category_id                 0\n",
      "publish_time                0\n",
      "tags                        0\n",
      "views                       0\n",
      "likes                       0\n",
      "dislikes                    0\n",
      "comment_count               0\n",
      "thumbnail_link              0\n",
      "comments_disabled           0\n",
      "ratings_disabled            0\n",
      "video_error_or_removed      0\n",
      "description               612\n",
      "dtype: int64\n",
      "Duplicates: 171\n",
      "Outliers in Views: 590\n",
      "Outliers in Likes: 782\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37770 entries, 0 to 38915\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                37770 non-null  object             \n",
      " 1   trending_date           37770 non-null  datetime64[ns]     \n",
      " 2   title                   37770 non-null  object             \n",
      " 3   channel_title           37770 non-null  object             \n",
      " 4   category_id             37770 non-null  int64              \n",
      " 5   publish_time            37770 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    37770 non-null  object             \n",
      " 7   views                   37770 non-null  int64              \n",
      " 8   likes                   37770 non-null  int64              \n",
      " 9   dislikes                37770 non-null  int64              \n",
      " 10  comment_count           37770 non-null  int64              \n",
      " 11  thumbnail_link          37770 non-null  object             \n",
      " 12  comments_disabled       37770 non-null  bool               \n",
      " 13  ratings_disabled        37770 non-null  bool               \n",
      " 14  video_error_or_removed  37770 non-null  bool               \n",
      " 15  description             37770 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.1+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          37770  37770.000000  3.777000e+04   \n",
      "mean   2018-02-22 00:04:36.791103744     16.950066  3.799872e+06   \n",
      "min              2017-11-14 00:00:00      1.000000  8.510000e+02   \n",
      "25%              2017-12-31 00:00:00     10.000000  2.421012e+05   \n",
      "50%              2018-02-19 00:00:00     20.000000  9.236230e+05   \n",
      "75%              2018-04-16 00:00:00     24.000000  3.304131e+06   \n",
      "max              2018-06-14 00:00:00     43.000000  6.293427e+07   \n",
      "std                              NaN      7.773488  7.857484e+06   \n",
      "\n",
      "              likes      dislikes  comment_count  \n",
      "count  3.777000e+04  3.777000e+04   3.777000e+04  \n",
      "mean   9.188222e+04  4.689755e+03   8.621443e+03  \n",
      "min    0.000000e+00  0.000000e+00   0.000000e+00  \n",
      "25%    5.639500e+03  1.920000e+02   6.520000e+02  \n",
      "50%    2.372550e+04  7.700000e+02   2.312500e+03  \n",
      "75%    9.971825e+04  2.945250e+03   8.270750e+03  \n",
      "max    1.180823e+06  1.065772e+06   1.059651e+06  \n",
      "std    1.623472e+05  1.789853e+04   1.991205e+04  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('GBvideos.csv')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_GBvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d27e5a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzwfHumJyYc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Sharry Mann: Cute Munda ( Song Teaser) | Parmi...</td>\n",
       "      <td>Lokdhun Punjabi</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-12T12:20:39.000Z</td>\n",
       "      <td>sharry mann|\"sharry mann new song\"|\"sharry man...</td>\n",
       "      <td>1096327</td>\n",
       "      <td>33966</td>\n",
       "      <td>798</td>\n",
       "      <td>882</td>\n",
       "      <td>https://i.ytimg.com/vi/kzwfHumJyYc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Presenting Sharry Mann latest Punjabi Song  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zUZ1z7FwLc8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>पीरियड्स के समय, पेट पर पति करता ऐसा, देखकर दं...</td>\n",
       "      <td>HJ NEWS</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T05:43:56.000Z</td>\n",
       "      <td>पीरियड्स के समय|\"पेट पर पति करता ऐसा\"|\"देखकर द...</td>\n",
       "      <td>590101</td>\n",
       "      <td>735</td>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/zUZ1z7FwLc8/default.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>पीरियड्स के समय, पेट पर पति करता ऐसा, देखकर दं...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10L1hZ9qa58</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Stylish Star Allu Arjun @ ChaySam Wedding Rece...</td>\n",
       "      <td>TFPC</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T15:48:08.000Z</td>\n",
       "      <td>Stylish Star Allu Arjun @ ChaySam Wedding Rece...</td>\n",
       "      <td>473988</td>\n",
       "      <td>2011</td>\n",
       "      <td>243</td>\n",
       "      <td>149</td>\n",
       "      <td>https://i.ytimg.com/vi/10L1hZ9qa58/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Watch Stylish Star Allu Arjun @ ChaySam Weddin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1vE8iiEg64</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eruma Saani | Tamil vs English</td>\n",
       "      <td>Eruma Saani</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T07:08:48.000Z</td>\n",
       "      <td>Eruma Saani|\"Tamil Comedy Videos\"|\"Films\"|\"Mov...</td>\n",
       "      <td>1242680</td>\n",
       "      <td>70353</td>\n",
       "      <td>1624</td>\n",
       "      <td>2684</td>\n",
       "      <td>https://i.ytimg.com/vi/N1vE8iiEg64/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>This video showcases the difference between pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kJzGH0PVQHQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>why Samantha became EMOTIONAL @ Samantha naga ...</td>\n",
       "      <td>Filmylooks</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T01:14:16.000Z</td>\n",
       "      <td>Filmylooks|\"latest news\"|\"telugu movies\"|\"telu...</td>\n",
       "      <td>464015</td>\n",
       "      <td>492</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>https://i.ytimg.com/vi/kJzGH0PVQHQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>why Samantha became EMOTIONAL @ Samantha naga ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  kzwfHumJyYc      17.14.11   \n",
       "1  zUZ1z7FwLc8      17.14.11   \n",
       "2  10L1hZ9qa58      17.14.11   \n",
       "3  N1vE8iiEg64      17.14.11   \n",
       "4  kJzGH0PVQHQ      17.14.11   \n",
       "\n",
       "                                               title    channel_title  \\\n",
       "0  Sharry Mann: Cute Munda ( Song Teaser) | Parmi...  Lokdhun Punjabi   \n",
       "1  पीरियड्स के समय, पेट पर पति करता ऐसा, देखकर दं...          HJ NEWS   \n",
       "2  Stylish Star Allu Arjun @ ChaySam Wedding Rece...             TFPC   \n",
       "3                     Eruma Saani | Tamil vs English      Eruma Saani   \n",
       "4  why Samantha became EMOTIONAL @ Samantha naga ...       Filmylooks   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0            1  2017-11-12T12:20:39.000Z   \n",
       "1           25  2017-11-13T05:43:56.000Z   \n",
       "2           24  2017-11-12T15:48:08.000Z   \n",
       "3           23  2017-11-12T07:08:48.000Z   \n",
       "4           24  2017-11-13T01:14:16.000Z   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  sharry mann|\"sharry mann new song\"|\"sharry man...  1096327  33966   \n",
       "1  पीरियड्स के समय|\"पेट पर पति करता ऐसा\"|\"देखकर द...   590101    735   \n",
       "2  Stylish Star Allu Arjun @ ChaySam Wedding Rece...   473988   2011   \n",
       "3  Eruma Saani|\"Tamil Comedy Videos\"|\"Films\"|\"Mov...  1242680  70353   \n",
       "4  Filmylooks|\"latest news\"|\"telugu movies\"|\"telu...   464015    492   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0       798            882  https://i.ytimg.com/vi/kzwfHumJyYc/default.jpg   \n",
       "1       904              0  https://i.ytimg.com/vi/zUZ1z7FwLc8/default.jpg   \n",
       "2       243            149  https://i.ytimg.com/vi/10L1hZ9qa58/default.jpg   \n",
       "3      1624           2684  https://i.ytimg.com/vi/N1vE8iiEg64/default.jpg   \n",
       "4       293             66  https://i.ytimg.com/vi/kJzGH0PVQHQ/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1               True             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Presenting Sharry Mann latest Punjabi Song  Cu...  \n",
       "1  पीरियड्स के समय, पेट पर पति करता ऐसा, देखकर दं...  \n",
       "2  Watch Stylish Star Allu Arjun @ ChaySam Weddin...  \n",
       "3  This video showcases the difference between pe...  \n",
       "4  why Samantha became EMOTIONAL @ Samantha naga ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"INvideos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ade9ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37352 entries, 0 to 37351\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                37352 non-null  object\n",
      " 1   trending_date           37352 non-null  object\n",
      " 2   title                   37352 non-null  object\n",
      " 3   channel_title           37352 non-null  object\n",
      " 4   category_id             37352 non-null  int64 \n",
      " 5   publish_time            37352 non-null  object\n",
      " 6   tags                    37352 non-null  object\n",
      " 7   views                   37352 non-null  int64 \n",
      " 8   likes                   37352 non-null  int64 \n",
      " 9   dislikes                37352 non-null  int64 \n",
      " 10  comment_count           37352 non-null  int64 \n",
      " 11  thumbnail_link          37352 non-null  object\n",
      " 12  comments_disabled       37352 non-null  bool  \n",
      " 13  ratings_disabled        37352 non-null  bool  \n",
      " 14  video_error_or_removed  37352 non-null  bool  \n",
      " 15  description             36791 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  37352.000000  3.735200e+04  3.735200e+04  3.735200e+04    37352.00000\n",
      "mean      21.576596  1.060478e+06  2.708272e+04  1.665082e+03     2676.99743\n",
      "std        6.556593  3.184932e+06  9.714510e+04  1.607617e+04    14868.31713\n",
      "min        1.000000  4.024000e+03  0.000000e+00  0.000000e+00        0.00000\n",
      "25%       23.000000  1.239155e+05  8.640000e+02  1.080000e+02       81.00000\n",
      "50%       24.000000  3.045860e+05  3.069000e+03  3.260000e+02      329.00000\n",
      "75%       24.000000  7.992912e+05  1.377425e+04  1.019250e+03     1285.00000\n",
      "max       43.000000  1.254322e+08  2.912710e+06  1.545017e+06   827755.00000\n",
      "[ 1 25 24 23 10 22 19 28 27 26 43 17 29  2 15 20 30]\n",
      "[False  True]\n",
      "video_id                    0\n",
      "trending_date               0\n",
      "title                       0\n",
      "channel_title               0\n",
      "category_id                 0\n",
      "publish_time                0\n",
      "tags                        0\n",
      "views                       0\n",
      "likes                       0\n",
      "dislikes                    0\n",
      "comment_count               0\n",
      "thumbnail_link              0\n",
      "comments_disabled           0\n",
      "ratings_disabled            0\n",
      "video_error_or_removed      0\n",
      "description               561\n",
      "dtype: int64\n",
      "Duplicates: 4263\n",
      "Outliers in Views: 471\n",
      "Outliers in Likes: 543\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32350 entries, 0 to 37330\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                32350 non-null  object             \n",
      " 1   trending_date           32350 non-null  datetime64[ns]     \n",
      " 2   title                   32350 non-null  object             \n",
      " 3   channel_title           32350 non-null  object             \n",
      " 4   category_id             32350 non-null  int64              \n",
      " 5   publish_time            32350 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    32350 non-null  object             \n",
      " 7   views                   32350 non-null  int64              \n",
      " 8   likes                   32350 non-null  int64              \n",
      " 9   dislikes                32350 non-null  int64              \n",
      " 10  comment_count           32350 non-null  int64              \n",
      " 11  thumbnail_link          32350 non-null  object             \n",
      " 12  comments_disabled       32350 non-null  bool               \n",
      " 13  ratings_disabled        32350 non-null  bool               \n",
      " 14  video_error_or_removed  32350 non-null  bool               \n",
      " 15  description             32350 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 3.5+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          32350  32350.000000  3.235000e+04   \n",
      "mean   2018-02-18 11:13:13.001545472     21.729150  6.686474e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  4.024000e+03   \n",
      "25%              2017-12-27 00:00:00     23.000000  1.101432e+05   \n",
      "50%              2018-02-13 00:00:00     24.000000  2.641460e+05   \n",
      "75%              2018-04-07 00:00:00     24.000000  6.761500e+05   \n",
      "max              2018-06-14 00:00:00     43.000000  1.043358e+07   \n",
      "std                              NaN      6.412232  1.196392e+06   \n",
      "\n",
      "               likes      dislikes  comment_count  \n",
      "count   32350.000000  32350.000000   32350.000000  \n",
      "mean    15018.860835    919.802998    1412.174807  \n",
      "min         0.000000      0.000000       0.000000  \n",
      "25%       763.000000     95.000000      69.000000  \n",
      "50%      2619.500000    276.000000     282.000000  \n",
      "75%     10635.750000    851.000000    1053.000000  \n",
      "max    311846.000000  81383.000000  295139.000000  \n",
      "std     35859.880624   2320.416284    4858.604784  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('INvideos.csv')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_INvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d5dfa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ugKfHgsmYw</td>\n",
       "      <td>18.07.02</td>\n",
       "      <td>é¸èªããªãåç´ã«è½ä¸ï¼è·¯ä¸ã®è»ã...</td>\n",
       "      <td>æäºéä¿¡æ åã»ã³ã¿ã¼</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-02-06T03:04:37.000Z</td>\n",
       "      <td>äºæ",
       "|\"ä½è³\"|\"ä½è³ç\"|\"ããªã³ãã¿ã...</td>\n",
       "      <td>188085</td>\n",
       "      <td>591</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/5ugKfHgsmYw/default.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ä½è³çç¥å¼å¸ã®æ°å®¶ã«å¢è½ããé¸ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohObafdd34Y</td>\n",
       "      <td>18.07.02</td>\n",
       "      <td>ã¤ããQ ãç¥­ãç·å®®å·Ãæè¶ å·¨å¤§ã...</td>\n",
       "      <td>ç¥è°·ãããª Kamiya Erina 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-06T04:01:56.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>90929</td>\n",
       "      <td>442</td>\n",
       "      <td>88</td>\n",
       "      <td>174</td>\n",
       "      <td>https://i.ytimg.com/vi/ohObafdd34Y/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aBr2kKAHN6M</td>\n",
       "      <td>18.07.02</td>\n",
       "      <td>Live Views of Starman</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-02-06T21:38:22.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>6408303</td>\n",
       "      <td>165892</td>\n",
       "      <td>2331</td>\n",
       "      <td>3006</td>\n",
       "      <td>https://i.ytimg.com/vi/aBr2kKAHN6M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5wNnwChvmsQ</td>\n",
       "      <td>18.07.02</td>\n",
       "      <td>æ±äº¬ãã£ãºãã¼ãªã¾ã¼ãã®å",
       "ã­ã£ã...</td>\n",
       "      <td>ã¢ã·ã¿ãã¯ãã¤</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-02-06T06:08:49.000Z</td>\n",
       "      <td>ã¢ã·ã¿ãã¯ãã¤</td>\n",
       "      <td>96255</td>\n",
       "      <td>1165</td>\n",
       "      <td>277</td>\n",
       "      <td>545</td>\n",
       "      <td>https://i.ytimg.com/vi/5wNnwChvmsQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>æ±äº¬ãã£ãºãã¼ãªã¾ã¼ãã®å",
       "ã­ã£ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B7J47qFvdsk</td>\n",
       "      <td>18.07.02</td>\n",
       "      <td>æ¦®åå¥ã",
       "ãè¡æã®æ­»ãã ãµãï¼æ ç...</td>\n",
       "      <td>ã·ãããã¥ãã¤</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-06T02:30:00.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>108408</td>\n",
       "      <td>1336</td>\n",
       "      <td>74</td>\n",
       "      <td>201</td>\n",
       "      <td>https://i.ytimg.com/vi/B7J47qFvdsk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>å®¶ã«å¸°ã£ã¦ãããµã©ãªã¼ãã³ã®ãã...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  5ugKfHgsmYw      18.07.02   \n",
       "1  ohObafdd34Y      18.07.02   \n",
       "2  aBr2kKAHN6M      18.07.02   \n",
       "3  5wNnwChvmsQ      18.07.02   \n",
       "4  B7J47qFvdsk      18.07.02   \n",
       "\n",
       "                                               title  \\\n",
       "0  é¸èªããªãåç´ã«è½ä¸ï¼è·¯ä¸ã®è»ã...   \n",
       "1  ã¤ããQ ãç¥­ãç·å®®å·Ãæè¶ å·¨å¤§ã...   \n",
       "2                              Live Views of Starman   \n",
       "3  æ±äº¬ãã£ãºãã¼ãªã¾ã¼ãã®å\n",
       "ã­ã£ã...   \n",
       "4  æ¦®åå¥ã\n",
       "ãè¡æã®æ­»ãã ãµãï¼æ ç...   \n",
       "\n",
       "                    channel_title  category_id              publish_time  \\\n",
       "0  æäºéä¿¡æ åã»ã³ã¿ã¼           25  2018-02-06T03:04:37.000Z   \n",
       "1  ç¥è°·ãããª Kamiya Erina 2            1  2018-02-06T04:01:56.000Z   \n",
       "2                          SpaceX           28  2018-02-06T21:38:22.000Z   \n",
       "3           ã¢ã·ã¿ãã¯ãã¤           25  2018-02-06T06:08:49.000Z   \n",
       "4           ã·ãããã¥ãã¤            1  2018-02-06T02:30:00.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0  äºæ\n",
       "|\"ä½è³\"|\"ä½è³ç\"|\"ããªã³ãã¿ã...   188085     591   \n",
       "1                                             [none]    90929     442   \n",
       "2                                             [none]  6408303  165892   \n",
       "3                              ã¢ã·ã¿ãã¯ãã¤    96255    1165   \n",
       "4                                             [none]   108408    1336   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0       189              0  https://i.ytimg.com/vi/5ugKfHgsmYw/default.jpg   \n",
       "1        88            174  https://i.ytimg.com/vi/ohObafdd34Y/default.jpg   \n",
       "2      2331           3006  https://i.ytimg.com/vi/aBr2kKAHN6M/default.jpg   \n",
       "3       277            545  https://i.ytimg.com/vi/5wNnwChvmsQ/default.jpg   \n",
       "4        74            201  https://i.ytimg.com/vi/B7J47qFvdsk/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0               True             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  ä½è³çç¥å¼å¸ã®æ°å®¶ã«å¢è½ããé¸ä...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  æ±äº¬ãã£ãºãã¼ãªã¾ã¼ãã®å\n",
       "ã­ã£ã...  \n",
       "4  å®¶ã«å¸°ã£ã¦ãããµã©ãªã¼ãã³ã®ãã...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('JPvideos.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0985a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20523 entries, 0 to 20522\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                20523 non-null  object\n",
      " 1   trending_date           20523 non-null  object\n",
      " 2   title                   20523 non-null  object\n",
      " 3   channel_title           20523 non-null  object\n",
      " 4   category_id             20523 non-null  int64 \n",
      " 5   publish_time            20523 non-null  object\n",
      " 6   tags                    20523 non-null  object\n",
      " 7   views                   20523 non-null  int64 \n",
      " 8   likes                   20523 non-null  int64 \n",
      " 9   dislikes                20523 non-null  int64 \n",
      " 10  comment_count           20523 non-null  int64 \n",
      " 11  thumbnail_link          20523 non-null  object\n",
      " 12  comments_disabled       20523 non-null  bool  \n",
      " 13  ratings_disabled        20523 non-null  bool  \n",
      " 14  video_error_or_removed  20523 non-null  bool  \n",
      " 15  description             18399 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "        category_id         views         likes       dislikes  comment_count\n",
      "count  20523.000000  2.052300e+04  2.052300e+04   20523.000000   20523.000000\n",
      "mean      19.807533  2.620215e+05  8.059587e+03     366.823613    1196.077864\n",
      "std        6.655895  1.294938e+06  8.384837e+04    2658.598540   14943.608305\n",
      "min        1.000000  7.980000e+02  0.000000e+00       0.000000       0.000000\n",
      "25%       17.000000  1.710000e+04  1.210000e+02       9.000000      19.000000\n",
      "50%       22.000000  6.408400e+04  6.480000e+02      43.000000     133.000000\n",
      "75%       24.000000  1.833670e+05  2.303000e+03     178.000000     488.000000\n",
      "max       29.000000  6.279639e+07  4.470923e+06  119053.000000  905925.000000\n",
      "[25  1 28 22 23 19 15 24 26  2 17 29 10 20 27]\n",
      "[ True False]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               2124\n",
      "dtype: int64\n",
      "Duplicates: 5677\n",
      "Outliers in Views: 110\n",
      "Outliers in Likes: 86\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14710 entries, 0 to 20497\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                14710 non-null  object             \n",
      " 1   trending_date           14710 non-null  datetime64[ns]     \n",
      " 2   title                   14710 non-null  object             \n",
      " 3   channel_title           14710 non-null  object             \n",
      " 4   category_id             14710 non-null  int64              \n",
      " 5   publish_time            14710 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    14710 non-null  object             \n",
      " 7   views                   14710 non-null  int64              \n",
      " 8   likes                   14710 non-null  int64              \n",
      " 9   dislikes                14710 non-null  int64              \n",
      " 10  comment_count           14710 non-null  int64              \n",
      " 11  thumbnail_link          14710 non-null  object             \n",
      " 12  comments_disabled       14710 non-null  bool               \n",
      " 13  ratings_disabled        14710 non-null  bool               \n",
      " 14  video_error_or_removed  14710 non-null  bool               \n",
      " 15  description             14710 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          14710  14710.000000  1.471000e+04   \n",
      "mean   2018-04-10 06:15:25.084976128     19.786608  1.791928e+05   \n",
      "min              2018-02-07 00:00:00      1.000000  7.980000e+02   \n",
      "25%              2018-03-09 00:00:00     17.000000  1.474025e+04   \n",
      "50%              2018-04-14 00:00:00     22.000000  5.377850e+04   \n",
      "75%              2018-05-09 00:00:00     24.000000  1.590132e+05   \n",
      "max              2018-06-14 00:00:00     29.000000  3.710825e+06   \n",
      "std                              NaN      6.658012  3.741980e+05   \n",
      "\n",
      "               likes      dislikes  comment_count  \n",
      "count   14710.000000  14710.000000   14710.000000  \n",
      "mean     3804.367165    236.623793     601.857512  \n",
      "min         0.000000      0.000000       0.000000  \n",
      "25%       101.000000      8.000000      15.000000  \n",
      "50%       548.000000     34.000000     109.000000  \n",
      "75%      2039.000000    149.000000     426.000000  \n",
      "max    222582.000000  38912.000000   56858.000000  \n",
      "std     14492.500026    982.527215    1934.393884  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('JPvideos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_JPvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b407ab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RxGQe4EeEpA</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ì¢ì by ë¯¼ì_ì¤ì¢",
       "ì _ì¢ë ëµê°</td>\n",
       "      <td>ë¼í¸ë§ì½ë¦¬ì</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T07:07:36.000Z</td>\n",
       "      <td>ë¼í¸ë§|\"ì¤ì¢",
       "ì \"|\"ì¢ë\"|\"ì¢ì\"|\"ì¬ë ...</td>\n",
       "      <td>156130</td>\n",
       "      <td>1422</td>\n",
       "      <td>40</td>\n",
       "      <td>272</td>\n",
       "      <td>https://i.ytimg.com/vi/RxGQe4EeEpA/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ì¤ì¢",
       "ì  'ì¢ë'ì ëµê° 'ì¢ì' ìµì´ ê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hH7wVE8OlQ0</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>JSA ê·ì ë¶íêµ° ì´ê²© ë¶ì</td>\n",
       "      <td>Edward</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T10:59:16.000Z</td>\n",
       "      <td>JSA|\"ê·ì\"|\"ë¶íêµ°\"|\"ì´ê²©\"|\"ë¶ì\"|\"JS...</td>\n",
       "      <td>76533</td>\n",
       "      <td>211</td>\n",
       "      <td>28</td>\n",
       "      <td>113</td>\n",
       "      <td>https://i.ytimg.com/vi/hH7wVE8OlQ0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[ì±ëAë¨ë",
       "]å ë³ì¬ íì¬ 'ììë¶ëª",
       "...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9V8bnWUmE9U</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ëëª°ë¼í¨ë°ë¦¬ ì´ëí ìì 2í (ë¹¼ë...</td>\n",
       "      <td>ëëª°ë¼í¨ë°ë¦¬ í«ì¼</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-11T07:16:08.000Z</td>\n",
       "      <td>ìëë¤ì¤|\"ë¹¼ë¹¼ë¡\"|\"í«ì¼\"|\"ëëª°ë¼í...</td>\n",
       "      <td>421409</td>\n",
       "      <td>5112</td>\n",
       "      <td>166</td>\n",
       "      <td>459</td>\n",
       "      <td>https://i.ytimg.com/vi/9V8bnWUmE9U/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>í¼ê°ì¤ë ê¼­ ì¶ì² ë¶íëë ¤ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_8py-t5R80</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>áá",
       "µáá",
       "§á¼áá",
       "¡á¨ ì¶êµ­ íì¥, ëì¹...</td>\n",
       "      <td>ë¯¸ëì´ëª½êµ¬</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-12T11:19:52.000Z</td>\n",
       "      <td>ì´ëª",
       "ë°|\"ì´ëª",
       "ë° ì¶êµ­ê¸ì§\"|\"ì´ëª",
       "ë° ...</td>\n",
       "      <td>222850</td>\n",
       "      <td>2093</td>\n",
       "      <td>173</td>\n",
       "      <td>1219</td>\n",
       "      <td>https://i.ytimg.com/vi/0_8py-t5R80/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ë¤ì¤ë ëêµ¬ê²ëê¹ ë£ê³  ë í íì </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bk55RbxiQdI</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ê¹ì¥ê²¸ì ë¬¼ë¬ê°ë¤ MBC ë",
       "¸ì¡° íí¸ì...</td>\n",
       "      <td>NocutV</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T11:08:59.000Z</td>\n",
       "      <td>nocutV|\"ë",
       "¸ì»·V\"|\"CBS\"|\"mbc\"|\"ê¹ì¥ê²¸\"|\"í´ì...</td>\n",
       "      <td>84466</td>\n",
       "      <td>1094</td>\n",
       "      <td>109</td>\n",
       "      <td>450</td>\n",
       "      <td>https://i.ytimg.com/vi/bk55RbxiQdI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ê¹ì¥ê²¸ MBC ì¬ì¥ì´ ê²°êµ­ í´ìëë¤.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  RxGQe4EeEpA      17.14.11   \n",
       "1  hH7wVE8OlQ0      17.14.11   \n",
       "2  9V8bnWUmE9U      17.14.11   \n",
       "3  0_8py-t5R80      17.14.11   \n",
       "4  bk55RbxiQdI      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0           ì¢ì by ë¯¼ì_ì¤ì¢\n",
       "ì _ì¢ë ëµê°   \n",
       "1                 JSA ê·ì ë¶íêµ° ì´ê²© ë¶ì   \n",
       "2  ëëª°ë¼í¨ë°ë¦¬ ì´ëí ìì 2í (ë¹¼ë...   \n",
       "3  áá\n",
       "µáá\n",
       "§á¼áá\n",
       "¡á¨ ì¶êµ­ íì¥, ëì¹...   \n",
       "4  ê¹ì¥ê²¸ì ë¬¼ë¬ê°ë¤ MBC ë\n",
       "¸ì¡° íí¸ì...   \n",
       "\n",
       "               channel_title  category_id              publish_time  \\\n",
       "0         ë¼í¸ë§ì½ë¦¬ì           22  2017-11-13T07:07:36.000Z   \n",
       "1                     Edward           25  2017-11-13T10:59:16.000Z   \n",
       "2  ëëª°ë¼í¨ë°ë¦¬ í«ì¼           22  2017-11-11T07:16:08.000Z   \n",
       "3            ë¯¸ëì´ëª½êµ¬           25  2017-11-12T11:19:52.000Z   \n",
       "4                     NocutV           25  2017-11-13T11:08:59.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  ë¼í¸ë§|\"ì¤ì¢\n",
       "ì \"|\"ì¢ë\"|\"ì¢ì\"|\"ì¬ë ...  156130   1422        40   \n",
       "1  JSA|\"ê·ì\"|\"ë¶íêµ°\"|\"ì´ê²©\"|\"ë¶ì\"|\"JS...   76533    211        28   \n",
       "2  ìëë¤ì¤|\"ë¹¼ë¹¼ë¡\"|\"í«ì¼\"|\"ëëª°ë¼í...  421409   5112       166   \n",
       "3  ì´ëª\n",
       "ë°|\"ì´ëª\n",
       "ë° ì¶êµ­ê¸ì§\"|\"ì´ëª\n",
       "ë° ...  222850   2093       173   \n",
       "4  nocutV|\"ë\n",
       "¸ì»·V\"|\"CBS\"|\"mbc\"|\"ê¹ì¥ê²¸\"|\"í´ì...   84466   1094       109   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0            272  https://i.ytimg.com/vi/RxGQe4EeEpA/default.jpg   \n",
       "1            113  https://i.ytimg.com/vi/hH7wVE8OlQ0/default.jpg   \n",
       "2            459  https://i.ytimg.com/vi/9V8bnWUmE9U/default.jpg   \n",
       "3           1219  https://i.ytimg.com/vi/0_8py-t5R80/default.jpg   \n",
       "4            450  https://i.ytimg.com/vi/bk55RbxiQdI/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  ì¤ì¢\n",
       "ì  'ì¢ë'ì ëµê° 'ì¢ì' ìµì´ ê...  \n",
       "1  [ì±ëAë¨ë\n",
       "]å ë³ì¬ íì¬ 'ììë¶ëª\n",
       "...  \n",
       "2            í¼ê°ì¤ë ê¼­ ì¶ì² ë¶íëë ¤ì  \n",
       "3    ë¤ì¤ë ëêµ¬ê²ëê¹ ë£ê³  ë í íì   \n",
       "4  ê¹ì¥ê²¸ MBC ì¬ì¥ì´ ê²°êµ­ í´ìëë¤.\\n...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('KRvideos.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "408c71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34567 entries, 0 to 34566\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                34567 non-null  object\n",
      " 1   trending_date           34567 non-null  object\n",
      " 2   title                   34567 non-null  object\n",
      " 3   channel_title           34567 non-null  object\n",
      " 4   category_id             34567 non-null  int64 \n",
      " 5   publish_time            34567 non-null  object\n",
      " 6   tags                    34567 non-null  object\n",
      " 7   views                   34567 non-null  int64 \n",
      " 8   likes                   34567 non-null  int64 \n",
      " 9   dislikes                34567 non-null  int64 \n",
      " 10  comment_count           34567 non-null  int64 \n",
      " 11  thumbnail_link          34567 non-null  object\n",
      " 12  comments_disabled       34567 non-null  bool  \n",
      " 13  ratings_disabled        34567 non-null  bool  \n",
      " 14  video_error_or_removed  34567 non-null  bool  \n",
      " 15  description             31404 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 3.5+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  34567.000000  3.456700e+04  3.456700e+04  3.456700e+04   3.456700e+04\n",
      "mean      21.137675  4.249473e+05  1.218642e+04  5.390980e+02   2.025383e+03\n",
      "std        6.675455  2.430637e+06  1.170531e+05  1.370852e+04   2.150677e+04\n",
      "min        1.000000  2.050000e+03  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       22.000000  4.776850e+04  4.120000e+02  2.100000e+01   1.050000e+02\n",
      "50%       24.000000  1.114960e+05  1.389000e+03  6.500000e+01   3.450000e+02\n",
      "75%       25.000000  2.788665e+05  3.704500e+03  1.750000e+02   9.290000e+02\n",
      "max       44.000000  1.138762e+08  5.150839e+06  1.470388e+06   1.142274e+06\n",
      "[22 25 17 19 23 10 24 15  1 43 28 20 29  2 27 26 44]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               3163\n",
      "dtype: int64\n",
      "Duplicates: 2316\n",
      "Outliers in Views: 200\n",
      "Outliers in Likes: 194\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31988 entries, 0 to 34566\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                31988 non-null  object             \n",
      " 1   trending_date           31988 non-null  datetime64[ns]     \n",
      " 2   title                   31988 non-null  object             \n",
      " 3   channel_title           31988 non-null  object             \n",
      " 4   category_id             31988 non-null  int64              \n",
      " 5   publish_time            31988 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    31988 non-null  object             \n",
      " 7   views                   31988 non-null  int64              \n",
      " 8   likes                   31988 non-null  int64              \n",
      " 9   dislikes                31988 non-null  int64              \n",
      " 10  comment_count           31988 non-null  int64              \n",
      " 11  thumbnail_link          31988 non-null  object             \n",
      " 12  comments_disabled       31988 non-null  bool               \n",
      " 13  ratings_disabled        31988 non-null  bool               \n",
      " 14  video_error_or_removed  31988 non-null  bool               \n",
      " 15  description             31988 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 3.5+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          31988  31988.000000  3.198800e+04   \n",
      "mean   2018-02-25 02:59:10.031261696     21.195448  2.757747e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  2.050000e+03   \n",
      "25%              2018-01-01 00:00:00     22.000000  4.615550e+04   \n",
      "50%              2018-02-23 00:00:00     24.000000  1.071615e+05   \n",
      "75%              2018-04-22 00:00:00     25.000000  2.669552e+05   \n",
      "max              2018-06-14 00:00:00     44.000000  7.664810e+06   \n",
      "std                              NaN      6.619889  5.525996e+05   \n",
      "\n",
      "               likes      dislikes  comment_count  \n",
      "count   31988.000000  31988.000000   31988.000000  \n",
      "mean     5035.135395    210.971020    1012.036983  \n",
      "min         0.000000      0.000000       0.000000  \n",
      "25%       397.000000     20.000000     100.000000  \n",
      "50%      1321.000000     62.000000     328.000000  \n",
      "75%      3517.250000    165.000000     879.250000  \n",
      "max    345197.000000  72335.000000  297747.000000  \n",
      "std     18925.423550    811.337855    3960.373575  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('KRvideos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_KRvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3834f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SbOwzAl9ZfQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>CapÃ­tulo 12 | MasterChef 2017</td>\n",
       "      <td>MasterChef 2017</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T06:06:22.000Z</td>\n",
       "      <td>MasterChef Junior 2017|\"TV Azteca\"|\"recetas\"|\"...</td>\n",
       "      <td>310130</td>\n",
       "      <td>4182</td>\n",
       "      <td>361</td>\n",
       "      <td>1836</td>\n",
       "      <td>https://i.ytimg.com/vi/SbOwzAl9ZfQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Disfruta la presencia del Chef Torreblanca en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klOV6Xh-DnI</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...</td>\n",
       "      <td>Micky Contreras Martinez</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T05:11:58.000Z</td>\n",
       "      <td>La Voz Mexico 7</td>\n",
       "      <td>104972</td>\n",
       "      <td>271</td>\n",
       "      <td>174</td>\n",
       "      <td>369</td>\n",
       "      <td>https://i.ytimg.com/vi/klOV6Xh-DnI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6L2ZF7Qzsbk</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>LOUIS CKAGÃ - EL PULSO DE LA REPÃBLICA</td>\n",
       "      <td>El Pulso De La RepÃºblica</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T17:00:02.000Z</td>\n",
       "      <td>Chumel Torres|\"El Pulso de la Republica\"|\"noti...</td>\n",
       "      <td>136064</td>\n",
       "      <td>10105</td>\n",
       "      <td>266</td>\n",
       "      <td>607</td>\n",
       "      <td>https://i.ytimg.com/vi/6L2ZF7Qzsbk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>La canciÃ³n del principio se llama âEste esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hcY52MFWMDM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Sismo de 6.7 sacude Costa Rica 12 Noviembre 2017</td>\n",
       "      <td>Casanare</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T03:47:10.000Z</td>\n",
       "      <td>temblor|\"costa rica\"|\"sismo en costa rica\"</td>\n",
       "      <td>96153</td>\n",
       "      <td>378</td>\n",
       "      <td>171</td>\n",
       "      <td>208</td>\n",
       "      <td>https://i.ytimg.com/vi/hcY52MFWMDM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>El video es de un Walmart en el pais centroame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_OXDcGPVAa4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>DOG HACKS | MUSAS LESSLIE LOS POLINESIOS</td>\n",
       "      <td>Musas</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-13T19:17:48.000Z</td>\n",
       "      <td>MUSAS|\"lesslie\"|\"karen\"|\"hacks\"|\"perros\"|\"dogs...</td>\n",
       "      <td>499965</td>\n",
       "      <td>57781</td>\n",
       "      <td>681</td>\n",
       "      <td>7428</td>\n",
       "      <td>https://i.ytimg.com/vi/_OXDcGPVAa4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MI HERMANO NARRA MI RUTINA DE MAQUILLAJE\\nhttp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  SbOwzAl9ZfQ      17.14.11   \n",
       "1  klOV6Xh-DnI      17.14.11   \n",
       "2  6L2ZF7Qzsbk      17.14.11   \n",
       "3  hcY52MFWMDM      17.14.11   \n",
       "4  _OXDcGPVAa4      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0                     CapÃ­tulo 12 | MasterChef 2017   \n",
       "1  ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...   \n",
       "2           LOUIS CKAGÃ - EL PULSO DE LA REPÃBLICA   \n",
       "3   Sismo de 6.7 sacude Costa Rica 12 Noviembre 2017   \n",
       "4           DOG HACKS | MUSAS LESSLIE LOS POLINESIOS   \n",
       "\n",
       "               channel_title  category_id              publish_time  \\\n",
       "0            MasterChef 2017           24  2017-11-13T06:06:22.000Z   \n",
       "1   Micky Contreras Martinez           22  2017-11-13T05:11:58.000Z   \n",
       "2  El Pulso De La RepÃºblica           25  2017-11-13T17:00:02.000Z   \n",
       "3                   Casanare           25  2017-11-13T03:47:10.000Z   \n",
       "4                      Musas           26  2017-11-13T19:17:48.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  MasterChef Junior 2017|\"TV Azteca\"|\"recetas\"|\"...  310130   4182       361   \n",
       "1                                    La Voz Mexico 7  104972    271       174   \n",
       "2  Chumel Torres|\"El Pulso de la Republica\"|\"noti...  136064  10105       266   \n",
       "3         temblor|\"costa rica\"|\"sismo en costa rica\"   96153    378       171   \n",
       "4  MUSAS|\"lesslie\"|\"karen\"|\"hacks\"|\"perros\"|\"dogs...  499965  57781       681   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0           1836  https://i.ytimg.com/vi/SbOwzAl9ZfQ/default.jpg   \n",
       "1            369  https://i.ytimg.com/vi/klOV6Xh-DnI/default.jpg   \n",
       "2            607  https://i.ytimg.com/vi/6L2ZF7Qzsbk/default.jpg   \n",
       "3            208  https://i.ytimg.com/vi/hcY52MFWMDM/default.jpg   \n",
       "4           7428  https://i.ytimg.com/vi/_OXDcGPVAa4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Disfruta la presencia del Chef Torreblanca en ...  \n",
       "1  ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...  \n",
       "2  La canciÃ³n del principio se llama âEste esp...  \n",
       "3  El video es de un Walmart en el pais centroame...  \n",
       "4  MI HERMANO NARRA MI RUTINA DE MAQUILLAJE\\nhttp...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MXvideos.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9554e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40451 entries, 0 to 40450\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40451 non-null  object\n",
      " 1   trending_date           40451 non-null  object\n",
      " 2   title                   40451 non-null  object\n",
      " 3   channel_title           40451 non-null  object\n",
      " 4   category_id             40451 non-null  int64 \n",
      " 5   publish_time            40451 non-null  object\n",
      " 6   tags                    40451 non-null  object\n",
      " 7   views                   40451 non-null  int64 \n",
      " 8   likes                   40451 non-null  int64 \n",
      " 9   dislikes                40451 non-null  int64 \n",
      " 10  comment_count           40451 non-null  int64 \n",
      " 11  thumbnail_link          40451 non-null  object\n",
      " 12  comments_disabled       40451 non-null  bool  \n",
      " 13  ratings_disabled        40451 non-null  bool  \n",
      " 14  video_error_or_removed  40451 non-null  bool  \n",
      " 15  description             36227 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.1+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40451.000000  4.045100e+04  4.045100e+04  4.045100e+04   40451.000000\n",
      "mean      21.003140  3.423820e+05  1.586184e+04  7.471604e+02    2039.660008\n",
      "std        5.878995  1.714691e+06  8.108987e+04  1.095358e+04   13938.031797\n",
      "min        1.000000  1.570000e+02  0.000000e+00  0.000000e+00       0.000000\n",
      "25%       20.000000  1.681300e+04  2.990000e+02  1.700000e+01      42.000000\n",
      "50%       24.000000  5.697300e+04  1.246000e+03  6.300000e+01     196.000000\n",
      "75%       24.000000  2.068940e+05  7.226000e+03  2.670000e+02     885.000000\n",
      "max       43.000000  1.009124e+08  4.470923e+06  1.353667e+06  905925.000000\n",
      "[24 22 25 26 10 23 17  2  1 29 27 28 20 15 19 43]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               4224\n",
      "dtype: int64\n",
      "Duplicates: 49\n",
      "Outliers in Views: 324\n",
      "Outliers in Likes: 402\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39901 entries, 0 to 40450\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                39901 non-null  object             \n",
      " 1   trending_date           39901 non-null  datetime64[ns]     \n",
      " 2   title                   39901 non-null  object             \n",
      " 3   channel_title           39901 non-null  object             \n",
      " 4   category_id             39901 non-null  int64              \n",
      " 5   publish_time            39901 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    39901 non-null  object             \n",
      " 7   views                   39901 non-null  int64              \n",
      " 8   likes                   39901 non-null  int64              \n",
      " 9   dislikes                39901 non-null  int64              \n",
      " 10  comment_count           39901 non-null  int64              \n",
      " 11  thumbnail_link          39901 non-null  object             \n",
      " 12  comments_disabled       39901 non-null  bool               \n",
      " 13  ratings_disabled        39901 non-null  bool               \n",
      " 14  video_error_or_removed  39901 non-null  bool               \n",
      " 15  description             39901 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          39901  39901.000000  3.990100e+04   \n",
      "mean   2018-02-26 02:45:41.164381696     21.077166  2.189259e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  1.570000e+02   \n",
      "25%              2018-01-03 00:00:00     22.000000  1.651600e+04   \n",
      "50%              2018-02-25 00:00:00     24.000000  5.518700e+04   \n",
      "75%              2018-04-22 00:00:00     24.000000  1.956980e+05   \n",
      "max              2018-06-14 00:00:00     43.000000  5.312227e+06   \n",
      "std                              NaN      5.827137  4.623469e+05   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   39901.000000   39901.000000   39901.000000  \n",
      "mean     9893.415278     441.629734    1329.129922  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%       292.000000      17.000000      41.000000  \n",
      "50%      1204.000000      61.000000     189.000000  \n",
      "75%      6697.000000     250.000000     827.000000  \n",
      "max    249448.000000  194855.000000  223802.000000  \n",
      "std     25496.215959    2545.293949    4626.260726  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('MXvideos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_MXvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8db0d56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gDuslQ9avLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ÐÐ°Ñ",
       "Ð°Ñ Ð¸ ÐÐ¾Ð»Ð¸Ð½Ð° ÑÑÐ°ÑÑÑ ÑÐºÐ¾...</td>\n",
       "      <td>Ð¢âÐ ÐÐÐÐÐ§</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T09:09:31.000Z</td>\n",
       "      <td>Ð·Ð°Ñ",
       "Ð°Ñ Ð¸ Ð¿Ð¾Ð»Ð¸Ð½Ð°|\"ÑÑÐ¸Ð¼ÑÑ ÑÐºÐ...</td>\n",
       "      <td>62408</td>\n",
       "      <td>334</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "      <td>https://i.ytimg.com/vi/gDuslQ9avLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ÐÐ½Ð°ÐºÐ¾Ð¼ÑÑÐµÑÑ, ÑÑÐ¾ ÐÐ°Ñ",
       "Ð°Ñ Ð¸ Ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOCJIFEA_jE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ÐÐ¸ÑÐ¶Ð° ÐÐµÐ¼Ð¾Ð² #29. ÐÐ¾Ð»ÑÑÐ¾Ð¸Ì Ð²...</td>\n",
       "      <td>Druzhko Show</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:32:11.000Z</td>\n",
       "      <td>Ð±Ð¸ÑÐ¶Ð° Ð¼ÐµÐ¼Ð¾Ð²|\"Ð»ÐµÐ² ÑÐ°Ð³Ð¸Ð½ÑÐ½\"|...</td>\n",
       "      <td>330043</td>\n",
       "      <td>43841</td>\n",
       "      <td>2244</td>\n",
       "      <td>2977</td>\n",
       "      <td>https://i.ytimg.com/vi/AOCJIFEA_jE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ð 29 Ð²ÑÐ¿ÑÑÐºÐµ ÐÑÑÐ¶ÐºÐ¾ Ð¨Ð¾Ñ Ð¡ÐµÑ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAWNQDgwwOM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Ð¥ÐÐÐ ÐÐ­ÐÐ - Ð¡ÐÐÐ Ð¡Ð ÐÐÐ Ð§Ð£Ð...</td>\n",
       "      <td>Ð®Ð»Ð¸Ðº</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T16:11:31.000Z</td>\n",
       "      <td>ÑÐ¼Ð¾Ñ|\"ÐºÐ¾Ð¼ÐµÐ´Ð¸Ñ\"|\"Ð²Ð»Ð¾Ð³\"|\"Ð±Ð»Ð¾Ð³...</td>\n",
       "      <td>424596</td>\n",
       "      <td>49854</td>\n",
       "      <td>714</td>\n",
       "      <td>2944</td>\n",
       "      <td>https://i.ytimg.com/vi/VAWNQDgwwOM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://kapitany.ru/!Yulik.cap - Ð¤Ð°ÐºÑÐ»ÑÑ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gknkFwKQfHg</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Ð¡Ð¾ÑÐ½Ð°Ñ ÐºÐµÑÐ°Ð´Ð¸Ð»ÑÑ Ñ ÐºÑÑÐ¸ÑÐµÐ¹</td>\n",
       "      <td>Hochland</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T06:51:10.000Z</td>\n",
       "      <td>Ñ",
       "Ð¾Ñ",
       "Ð»Ð°Ð½Ð´|\"ÑÑÑ\"|\"ÑÐµÑÐµÐ¿ÑÑ\"|\"ÐºÐ°...</td>\n",
       "      <td>112851</td>\n",
       "      <td>3566</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>https://i.ytimg.com/vi/gknkFwKQfHg/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>*** ÐºÐ°Ðº Ð³Ð¾ÑÐ¾Ð²Ð¸ÑÑ ÑÐµÑÑÐ¾ÑÐ°Ð½Ð½...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3sYvZcwzZr8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ÐÐÐÐÐ« Ð ÐÐÐÐ¢ÐÐÐÐ ÐÐ Ð¨ÐÐÐÐ¬Ð...</td>\n",
       "      <td>Ð¡Ð¾Ð²ÐµÑÐ³Ð¾Ð½</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T16:52:36.000Z</td>\n",
       "      <td>Ð¡Ð¾Ð²ÐµÑÐ³Ð¾Ð½|\"Sovergon\"|\"ÐºÐ»Ð¸Ð¿Ñ\"|\"ÑÐ¾...</td>\n",
       "      <td>243469</td>\n",
       "      <td>36216</td>\n",
       "      <td>631</td>\n",
       "      <td>1692</td>\n",
       "      <td>https://i.ytimg.com/vi/3sYvZcwzZr8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>â ÐÐÐÐÐ£Ð Ð¡ ÐÐÐÐÐ¢ÐÐÐ«: http://ka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  gDuslQ9avLc      17.14.11   \n",
       "1  AOCJIFEA_jE      17.14.11   \n",
       "2  VAWNQDgwwOM      17.14.11   \n",
       "3  gknkFwKQfHg      17.14.11   \n",
       "4  3sYvZcwzZr8      17.14.11   \n",
       "\n",
       "                                               title       channel_title  \\\n",
       "0  ÐÐ°Ñ\n",
       "Ð°Ñ Ð¸ ÐÐ¾Ð»Ð¸Ð½Ð° ÑÑÐ°ÑÑÑ ÑÐºÐ¾...  Ð¢âÐ ÐÐÐÐÐ§   \n",
       "1  ÐÐ¸ÑÐ¶Ð° ÐÐµÐ¼Ð¾Ð² #29. ÐÐ¾Ð»ÑÑÐ¾Ð¸Ì Ð²...        Druzhko Show   \n",
       "2  Ð¥ÐÐÐ ÐÐ­ÐÐ - Ð¡ÐÐÐ Ð¡Ð ÐÐÐ Ð§Ð£Ð...            Ð®Ð»Ð¸Ðº   \n",
       "3  Ð¡Ð¾ÑÐ½Ð°Ñ ÐºÐµÑÐ°Ð´Ð¸Ð»ÑÑ Ñ ÐºÑÑÐ¸ÑÐµÐ¹            Hochland   \n",
       "4  ÐÐÐÐÐ« Ð ÐÐÐÐ¢ÐÐÐÐ ÐÐ Ð¨ÐÐÐÐ¬Ð...    Ð¡Ð¾Ð²ÐµÑÐ³Ð¾Ð½   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T09:09:31.000Z   \n",
       "1           22  2017-11-13T17:32:11.000Z   \n",
       "2           24  2017-11-13T16:11:31.000Z   \n",
       "3           22  2017-11-13T06:51:10.000Z   \n",
       "4           24  2017-11-13T16:52:36.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  Ð·Ð°Ñ\n",
       "Ð°Ñ Ð¸ Ð¿Ð¾Ð»Ð¸Ð½Ð°|\"ÑÑÐ¸Ð¼ÑÑ ÑÐºÐ...   62408    334       190   \n",
       "1  Ð±Ð¸ÑÐ¶Ð° Ð¼ÐµÐ¼Ð¾Ð²|\"Ð»ÐµÐ² ÑÐ°Ð³Ð¸Ð½ÑÐ½\"|...  330043  43841      2244   \n",
       "2  ÑÐ¼Ð¾Ñ|\"ÐºÐ¾Ð¼ÐµÐ´Ð¸Ñ\"|\"Ð²Ð»Ð¾Ð³\"|\"Ð±Ð»Ð¾Ð³...  424596  49854       714   \n",
       "3  Ñ\n",
       "Ð¾Ñ\n",
       "Ð»Ð°Ð½Ð´|\"ÑÑÑ\"|\"ÑÐµÑÐµÐ¿ÑÑ\"|\"ÐºÐ°...  112851   3566       122   \n",
       "4  Ð¡Ð¾Ð²ÐµÑÐ³Ð¾Ð½|\"Sovergon\"|\"ÐºÐ»Ð¸Ð¿Ñ\"|\"ÑÐ¾...  243469  36216       631   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0             50  https://i.ytimg.com/vi/gDuslQ9avLc/default.jpg   \n",
       "1           2977  https://i.ytimg.com/vi/AOCJIFEA_jE/default.jpg   \n",
       "2           2944  https://i.ytimg.com/vi/VAWNQDgwwOM/default.jpg   \n",
       "3             80  https://i.ytimg.com/vi/gknkFwKQfHg/default.jpg   \n",
       "4           1692  https://i.ytimg.com/vi/3sYvZcwzZr8/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  ÐÐ½Ð°ÐºÐ¾Ð¼ÑÑÐµÑÑ, ÑÑÐ¾ ÐÐ°Ñ\n",
       "Ð°Ñ Ð¸ Ð...  \n",
       "1  Ð 29 Ð²ÑÐ¿ÑÑÐºÐµ ÐÑÑÐ¶ÐºÐ¾ Ð¨Ð¾Ñ Ð¡ÐµÑ...  \n",
       "2  http://kapitany.ru/!Yulik.cap - Ð¤Ð°ÐºÑÐ»ÑÑ...  \n",
       "3  *** ÐºÐ°Ðº Ð³Ð¾ÑÐ¾Ð²Ð¸ÑÑ ÑÐµÑÑÐ¾ÑÐ°Ð½Ð½...  \n",
       "4  â ÐÐÐÐÐ£Ð Ð¡ ÐÐÐÐÐ¢ÐÐÐ«: http://ka...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('RUvideos.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ae558b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40739 entries, 0 to 40738\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40739 non-null  object\n",
      " 1   trending_date           40739 non-null  object\n",
      " 2   title                   40739 non-null  object\n",
      " 3   channel_title           40739 non-null  object\n",
      " 4   category_id             40739 non-null  int64 \n",
      " 5   publish_time            40739 non-null  object\n",
      " 6   tags                    40739 non-null  object\n",
      " 7   views                   40739 non-null  int64 \n",
      " 8   likes                   40739 non-null  int64 \n",
      " 9   dislikes                40739 non-null  int64 \n",
      " 10  comment_count           40739 non-null  int64 \n",
      " 11  thumbnail_link          40739 non-null  object\n",
      " 12  comments_disabled       40739 non-null  bool  \n",
      " 13  ratings_disabled        40739 non-null  bool  \n",
      " 14  video_error_or_removed  40739 non-null  bool  \n",
      " 15  description             38275 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes       dislikes  comment_count\n",
      "count  40739.000000  4.073900e+04  4.073900e+04   40739.000000   40739.000000\n",
      "mean      20.261936  2.407152e+05  1.243522e+04    1475.199612    1775.231179\n",
      "std        7.890955  9.345111e+05  6.038280e+04    8582.480809   11275.028305\n",
      "min        1.000000  1.170000e+02  0.000000e+00       0.000000       0.000000\n",
      "25%       20.000000  2.258750e+04  4.025000e+02      31.000000      73.000000\n",
      "50%       22.000000  6.631600e+04  1.880000e+03     128.000000     309.000000\n",
      "75%       25.000000  1.951310e+05  7.791000e+03     586.000000    1107.000000\n",
      "max       43.000000  6.279639e+07  4.470923e+06  884967.000000  905925.000000\n",
      "[22 24 28 23 27 17  2 25 15 20  1 43 26 10 29 19 30]\n",
      "[False  True]\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               2464\n",
      "dtype: int64\n",
      "Duplicates: 46\n",
      "Outliers in Views: 336\n",
      "Outliers in Likes: 356\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40185 entries, 0 to 40738\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                40185 non-null  object             \n",
      " 1   trending_date           40185 non-null  datetime64[ns]     \n",
      " 2   title                   40185 non-null  object             \n",
      " 3   channel_title           40185 non-null  object             \n",
      " 4   category_id             40185 non-null  int64              \n",
      " 5   publish_time            40185 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    40185 non-null  object             \n",
      " 7   views                   40185 non-null  int64              \n",
      " 8   likes                   40185 non-null  int64              \n",
      " 9   dislikes                40185 non-null  int64              \n",
      " 10  comment_count           40185 non-null  int64              \n",
      " 11  thumbnail_link          40185 non-null  object             \n",
      " 12  comments_disabled       40185 non-null  bool               \n",
      " 13  ratings_disabled        40185 non-null  bool               \n",
      " 14  video_error_or_removed  40185 non-null  bool               \n",
      " 15  description             40185 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          40185  40185.000000  4.018500e+04   \n",
      "mean   2018-02-26 13:27:50.862262016     20.283340  1.783448e+05   \n",
      "min              2017-11-14 00:00:00      1.000000  1.170000e+02   \n",
      "25%              2018-01-03 00:00:00     20.000000  2.223100e+04   \n",
      "50%              2018-02-25 00:00:00     22.000000  6.451600e+04   \n",
      "75%              2018-04-23 00:00:00     25.000000  1.850420e+05   \n",
      "max              2018-06-14 00:00:00     43.000000  2.878726e+06   \n",
      "std                              NaN      7.893266  3.153612e+05   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   40185.000000   40185.000000   40185.000000  \n",
      "mean     8701.781436    1206.808386    1280.323106  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%       393.000000      31.000000      72.000000  \n",
      "50%      1812.000000     124.000000     299.000000  \n",
      "75%      7303.000000     543.000000    1049.000000  \n",
      "max    180637.000000  212742.000000  177686.000000  \n",
      "std     19594.941605    5366.045854    3941.778484  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('RUvideos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_RUvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61ada004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO â¶ \\n\\nSUBSCRIBE âº ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "4  d380meD0W0M      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "4                           I Dare You: GOING BALD!?               nigahiga   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "4           24  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
       "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
       "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO â¶ \\n\\nSUBSCRIBE âº ...  \n",
       "3  Today we find out if Link is a Nickelback amat...  \n",
       "4  I know it's been a while since we did this sho...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('USvideos.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd5d7841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40949 entries, 0 to 40948\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40949 non-null  object\n",
      " 1   trending_date           40949 non-null  object\n",
      " 2   title                   40949 non-null  object\n",
      " 3   channel_title           40949 non-null  object\n",
      " 4   category_id             40949 non-null  int64 \n",
      " 5   publish_time            40949 non-null  object\n",
      " 6   tags                    40949 non-null  object\n",
      " 7   views                   40949 non-null  int64 \n",
      " 8   likes                   40949 non-null  int64 \n",
      " 9   dislikes                40949 non-null  int64 \n",
      " 10  comment_count           40949 non-null  int64 \n",
      " 11  thumbnail_link          40949 non-null  object\n",
      " 12  comments_disabled       40949 non-null  bool  \n",
      " 13  ratings_disabled        40949 non-null  bool  \n",
      " 14  video_error_or_removed  40949 non-null  bool  \n",
      " 15  description             40379 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40949.000000  4.094900e+04  4.094900e+04  4.094900e+04   4.094900e+04\n",
      "mean      19.972429  2.360785e+06  7.426670e+04  3.711401e+03   8.446804e+03\n",
      "std        7.568327  7.394114e+06  2.288853e+05  2.902971e+04   3.743049e+04\n",
      "min        1.000000  5.490000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       17.000000  2.423290e+05  5.424000e+03  2.020000e+02   6.140000e+02\n",
      "50%       24.000000  6.818610e+05  1.809100e+04  6.310000e+02   1.856000e+03\n",
      "75%       25.000000  1.823157e+06  5.541700e+04  1.938000e+03   5.755000e+03\n",
      "max       43.000000  2.252119e+08  5.613827e+06  1.674420e+06   1.361580e+06\n",
      "[22 24 23 28  1 25 17 10 15 27 26  2 19 20 29 43]\n",
      "[False  True]\n",
      "video_id                    0\n",
      "trending_date               0\n",
      "title                       0\n",
      "channel_title               0\n",
      "category_id                 0\n",
      "publish_time                0\n",
      "tags                        0\n",
      "views                       0\n",
      "likes                       0\n",
      "dislikes                    0\n",
      "comment_count               0\n",
      "thumbnail_link              0\n",
      "comments_disabled           0\n",
      "ratings_disabled            0\n",
      "video_error_or_removed      0\n",
      "description               570\n",
      "dtype: int64\n",
      "Duplicates: 48\n",
      "Outliers in Views: 519\n",
      "Outliers in Likes: 581\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40162 entries, 0 to 40948\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                40162 non-null  object             \n",
      " 1   trending_date           40162 non-null  datetime64[ns]     \n",
      " 2   title                   40162 non-null  object             \n",
      " 3   channel_title           40162 non-null  object             \n",
      " 4   category_id             40162 non-null  int64              \n",
      " 5   publish_time            40162 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    40162 non-null  object             \n",
      " 7   views                   40162 non-null  int64              \n",
      " 8   likes                   40162 non-null  int64              \n",
      " 9   dislikes                40162 non-null  int64              \n",
      " 10  comment_count           40162 non-null  int64              \n",
      " 11  thumbnail_link          40162 non-null  object             \n",
      " 12  comments_disabled       40162 non-null  bool               \n",
      " 13  ratings_disabled        40162 non-null  bool               \n",
      " 14  video_error_or_removed  40162 non-null  bool               \n",
      " 15  description             40162 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "                       trending_date   category_id         views  \\\n",
      "count                          40162  40162.000000  4.016200e+04   \n",
      "mean   2018-02-26 12:40:37.408495616     20.100866  1.653501e+06   \n",
      "min              2017-11-14 00:00:00      1.000000  5.490000e+02   \n",
      "25%              2018-01-03 00:00:00     17.000000  2.365218e+05   \n",
      "50%              2018-02-25 00:00:00     24.000000  6.556275e+05   \n",
      "75%              2018-04-23 00:00:00     25.000000  1.706136e+06   \n",
      "max              2018-06-14 00:00:00     43.000000  2.442317e+07   \n",
      "std                              NaN      7.526718  2.882360e+06   \n",
      "\n",
      "               likes       dislikes  comment_count  \n",
      "count   40162.000000   40162.000000   40162.000000  \n",
      "mean    51594.500124    2338.797072    5715.476520  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%      5261.250000     197.000000     599.000000  \n",
      "50%     17371.000000     609.000000    1793.000000  \n",
      "75%     51686.250000    1808.000000    5415.500000  \n",
      "max    759589.000000  228426.000000  383762.000000  \n",
      "std     91548.010608    8108.399968   12832.733364  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assume it's a CSV for now)\n",
    "df = pd.read_csv('USvideos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Data Integrity Check ###\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Get descriptive statistics for numerical columns\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "print(df['category_id'].unique())  # Unique categories\n",
    "print(df['comments_disabled'].unique())  # Ensure comments_disabled is either True/False\n",
    "\n",
    "### 2. Handling Missing Data ###\n",
    "\n",
    "# Check for missing data in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (Example: fill missing 'description' with 'No description')\n",
    "df['description'].fillna('No description', inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing data in important columns like 'views', 'likes'\n",
    "df.dropna(subset=['views', 'likes', 'dislikes'], inplace=True)\n",
    "\n",
    "### 3. Duplicate Removal ###\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "print(f'Duplicates: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "### 4. Standardization ###\n",
    "\n",
    "# Standardize 'publish_time' and 'trending_date' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# Standardize text columns by trimming spaces and lowercasing\n",
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df['channel_title'] = df['channel_title'].str.strip().str.lower()\n",
    "\n",
    "### 5. Outlier Detection ###\n",
    "\n",
    "# Check for outliers in numerical columns such as 'views', 'likes', 'dislikes'\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Z-score to identify outliers\n",
    "from scipy import stats\n",
    "df['views_zscore'] = np.abs(stats.zscore(df['views']))\n",
    "df['likes_zscore'] = np.abs(stats.zscore(df['likes']))\n",
    "\n",
    "# Set a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_views = df[df['views_zscore'] > 3]\n",
    "outliers_likes = df[df['likes_zscore'] > 3]\n",
    "\n",
    "print(f'Outliers in Views: {outliers_views.shape[0]}')\n",
    "print(f'Outliers in Likes: {outliers_likes.shape[0]}')\n",
    "\n",
    "# Optionally remove outliers\n",
    "df = df[(df['views_zscore'] <= 3) & (df['likes_zscore'] <= 3)]\n",
    "\n",
    "# Drop the Z-score columns as they are no longer needed\n",
    "df.drop(columns=['views_zscore', 'likes_zscore'], inplace=True)\n",
    "\n",
    "### Final Validation ###\n",
    "\n",
    "# After cleaning, recheck the data\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset_USvideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b387c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
